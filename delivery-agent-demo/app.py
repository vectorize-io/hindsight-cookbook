"""
Delivery Agent Demo - Streamlit App

A retro-style sprite-based demo showcasing how AI agents learn
to navigate using Hindsight memory.
"""

import streamlit as st
import streamlit.components.v1 as components
import time
import json
import os
import uuid
import random
import traceback
import threading
import queue
import warnings
import logging
import pandas as pd
from dotenv import load_dotenv

# Suppress noisy aiohttp warnings about unclosed client sessions
warnings.filterwarnings("ignore", message="Unclosed client session")
warnings.filterwarnings("ignore", message="Unclosed connector")
logging.getLogger("asyncio").setLevel(logging.ERROR)

# Queue storage using st.cache_resource to survive Streamlit reruns
# Regular module-level dicts get reset when Streamlit reimports the module
@st.cache_resource
def _get_queue_storage() -> dict:
    """Get the persistent queue storage dict. Survives Streamlit reruns."""
    return {}


@st.cache_resource
def _get_cancel_storage() -> dict:
    """Get the persistent cancellation event storage. Survives Streamlit reruns."""
    return {}


def _get_or_create_queue(session_id: str) -> queue.Queue:
    """Get the queue for this session, creating if needed."""
    storage = _get_queue_storage()
    if session_id not in storage:
        storage[session_id] = queue.Queue()
    return storage[session_id]


def _get_or_create_cancel_event(session_id: str) -> threading.Event:
    """Get the cancellation event for this session, creating if needed."""
    storage = _get_cancel_storage()
    if session_id not in storage:
        storage[session_id] = threading.Event()
    return storage[session_id]


def _cancel_delivery(session_id: str):
    """Signal cancellation for the delivery in this session."""
    storage = _get_cancel_storage()
    if session_id in storage:
        storage[session_id].set()


def _reset_cancel_event(session_id: str):
    """Reset the cancellation event for a new delivery."""
    storage = _get_cancel_storage()
    if session_id in storage:
        storage[session_id].clear()
    else:
        storage[session_id] = threading.Event()


def _clear_queue(session_id: str):
    """Clear and remove the queue for this session.

    Returns the 'complete' item if found, so caller can process it.
    """
    storage = _get_queue_storage()
    complete_item = None
    if session_id in storage:
        # Drain any remaining items, but capture 'complete' for processing
        q = storage[session_id]
        while True:
            try:
                item = q.get_nowait()
                if item.get("type") == "complete":
                    complete_item = item
            except queue.Empty:
                break
        del storage[session_id]
    return complete_item


import hindsight_litellm
from building import get_building, reset_building, Package


def _process_complete_item(complete_item):
    """Process a 'complete' item to update stats and history."""
    if complete_item is None:
        return
    # Don't count cancelled deliveries in stats/history
    if complete_item.get("cancelled"):
        return
    st.session_state.total_steps += complete_item["steps"]
    if complete_item["success"]:
        st.session_state.deliveries_completed += 1
    st.session_state.delivery_history.append({
        "package": st.session_state.get("last_package_info", "Unknown"),
        "success": complete_item["success"],
        "steps": complete_item["steps"],
    })
from agent import DeliveryAgent, ActionEvent
from agent_tools import AgentTools, TOOL_DEFINITIONS, execute_tool
from game_renderer import generate_game_html
import memory
from evaluation import (
    EvalConfig,
    EVAL_CONFIG_SETTINGS,
    EvaluationRunner,
    DeliveryData,
    StepData,
    compute_optimal_path,
    categorize_error,
    check_memory_relevance,
    generate_summary,
    generate_report_markdown,
    get_building_layout_dict,
)
from building import Side

# Load environment variables
load_dotenv()

# Debug mode - set to True to enable verbose logging to /tmp/demo.log
DEBUG = False

def _debug_log(msg: str):
    """Write to debug log only if DEBUG is enabled."""
    if DEBUG:
        with open("/tmp/demo.log", "a") as f:
            f.write(f"{msg}\n")

# Page config
st.set_page_config(
    page_title="Delivery Agent Demo",
    page_icon="ðŸ“¦",
    layout="wide"
)


def _format_messages_for_retain(messages: list) -> str:
    """Format conversation messages for explicit retain to Hindsight.

    This is used to store the final conversation when a delivery completes,
    since the automatic LLM callback won't capture the final tool results.
    """
    items = []
    for msg in messages:
        role = msg.get("role", "").upper()
        content = msg.get("content", "")
        tool_calls = msg.get("tool_calls", [])

        # Skip system messages
        if role == "SYSTEM":
            continue

        # Handle tool results
        if role == "TOOL":
            items.append(f"TOOL_RESULT: {content}")
            continue

        # Handle assistant with tool calls
        if tool_calls:
            tc_strs = []
            for tc in tool_calls:
                if hasattr(tc, 'function'):
                    tc_strs.append(f"{tc.function.name}({tc.function.arguments})")
                elif isinstance(tc, dict) and 'function' in tc:
                    func = tc['function']
                    tc_strs.append(f"{func.get('name', '')}({func.get('arguments', '')})")
            if tc_strs:
                items.append(f"ASSISTANT_TOOL_CALLS: {'; '.join(tc_strs)}")
            if content:
                items.append(f"ASSISTANT: {content}")
            continue

        # Regular messages
        if content:
            label = "USER" if role == "USER" else "ASSISTANT"
            items.append(f"{label}: {content}")

    return "\n\n".join(items)


def _run_delivery_in_background(
    action_queue: queue.Queue,
    building,
    package: Package,
    model: str,
    max_steps: int = None,
    cancel_event: threading.Event = None,
):
    """Run a delivery in a background thread, pushing actions to queue.

    This allows the UI to animate actions as they happen while the agent
    runs at full speed without waiting for animations.

    Args:
        action_queue: Thread-safe queue to push actions to
        building: The building to navigate
        package: The package to deliver
        model: LLM model to use
        max_steps: Maximum steps (None = no limit)
        cancel_event: Threading event to signal cancellation

    The queue receives dicts with keys:
        - type: "step", "success", "error", "step_limit", "cancelled", "memory_storing", "memory_stored", "complete"
        - For "step": Combined LLM call + tool execution (tool_name, tool_result, floor, side, timing, prompt, llm_response)
        - For "action": Fallback for non-tool responses (tool_name, result, floor, side, timing)
        - For "success"/"error"/"step_limit"/"cancelled": message
        - For "memory_storing"/"memory_stored": step, timing (for stored)
        - For "complete": success (bool), steps (int), messages (list), cancelled (bool)
    """
    from building import AgentState

    agent_state = AgentState()
    agent_state.current_package = package
    cancelled = False

    messages = [
        {"role": "system", "content": "You are a delivery agent. Use the tools provided to get it delivered."},
        {"role": "user", "content": f"Please deliver this package: {package}"}
    ]

    tools = AgentTools(building, agent_state)
    success = False
    error_msg = None

    try:
        while max_steps is None or agent_state.steps_taken < max_steps:
            # Check for cancellation
            if cancel_event and cancel_event.is_set():
                cancelled = True
                action_queue.put({
                    "type": "cancelled",
                    "message": "Delivery cancelled by user",
                })
                break

            t0 = time.time()

            _debug_log(f"[Step {agent_state.steps_taken + 1}] Calling LLM with {len(messages)} messages")

            response = memory.completion(
                model=model,
                messages=messages,
                tools=TOOL_DEFINITIONS,
                tool_choice="required",
                timeout=30
            )

            t1 = time.time()
            llm_duration = t1 - t0

            message = response.choices[0].message

            # Get injection debug info AFTER completion
            injection_info = {}
            try:
                import hindsight_litellm
                injection_debug = hindsight_litellm.get_last_injection_debug()
                if injection_debug:
                    injection_info = {
                        "injected": injection_debug.injected,
                        "memories_count": injection_debug.results_count or 0,
                        "error": str(injection_debug.error) if injection_debug.error else None,
                        "memory_context": injection_debug.memory_context,  # The actual injected text
                    }
            except Exception:
                pass  # Silently ignore if not available

            tool_names = [tc.function.name for tc in (message.tool_calls or [])]
            _debug_log(f"[Step {agent_state.steps_taken + 1}] Response in {llm_duration:.2f}s: {tool_names}")

            if message.tool_calls:
                tool_results = []
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}

                    result = execute_tool(tools, tool_name, arguments)

                    tool_results.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "content": result
                    })

                    # Push combined step item with LLM info and action result
                    action_queue.put({
                        "type": "step",
                        "step": agent_state.steps_taken,
                        "prompt": {
                            "messages": [dict(m) for m in messages],  # Shallow copy each message dict
                            "tools": TOOL_DEFINITIONS,
                            "_hindsight_injection": injection_info,  # Add injection debug info
                        },
                        "llm_response": {
                            "content": message.content,
                            "tool_calls": [{"name": tc.function.name, "arguments": tc.function.arguments} for tc in (message.tool_calls or [])]
                        },
                        "tool_name": tool_name,
                        "tool_result": result,
                        "floor": agent_state.floor,
                        "side": agent_state.side.value,
                        "timing": llm_duration,
                    })

                    if "SUCCESS!" in result:
                        success = True
                        action_queue.put({
                            "type": "success",
                            "message": result,
                        })
                        break

                # Serialize tool_calls to dicts for JSON compatibility
                serialized_tool_calls = [
                    {"id": tc.id, "type": "function", "function": {"name": tc.function.name, "arguments": tc.function.arguments}}
                    for tc in message.tool_calls
                ] if message.tool_calls else []
                messages.append({"role": "assistant", "content": message.content, "tool_calls": serialized_tool_calls})
                messages.extend(tool_results)

                if success:
                    # Store to memory on success
                    action_queue.put({
                        "type": "memory_storing",
                        "step": agent_state.steps_taken,
                    })
                    final_convo = _format_messages_for_retain(messages)
                    t_store = time.time()
                    memory.retain(final_convo)
                    store_duration = time.time() - t_store
                    action_queue.put({
                        "type": "memory_stored",
                        "step": agent_state.steps_taken,
                        "timing": store_duration,
                    })
                    break

                # Check step limit
                if max_steps is not None and agent_state.steps_taken >= max_steps:
                    action_queue.put({
                        "type": "step_limit",
                        "message": f"Exceeded {max_steps} step limit",
                    })
                    break
            else:
                # No tool calls - nudge to use tools
                if message.content:
                    action_queue.put({
                        "type": "action",
                        "step": agent_state.steps_taken,
                        "tool_name": "ðŸ’¬ response",
                        "result": message.content,
                        "floor": agent_state.floor,
                        "side": agent_state.side.value,
                        "timing": llm_duration,
                    })
                messages.append({"role": "assistant", "content": message.content})
                messages.append({"role": "user", "content": "Use the available tools to complete the delivery."})

    except Exception as e:
        error_msg = str(e)
        action_queue.put({
            "type": "error",
            "message": error_msg,
            "traceback": traceback.format_exc(),
        })

    # Signal completion
    action_queue.put({
        "type": "complete",
        "success": success,
        "steps": agent_state.steps_taken,
        "messages": messages,
        "error": error_msg,
        "cancelled": cancelled,
    })


def _run_single_delivery_ff(building, include_business: bool, delivery_counter: int, max_steps: int = None, sync_storage: bool = False):
    """Run a single delivery to completion without Streamlit reruns.

    This is optimized for fast-forward mode - no UI updates, minimal overhead.

    Args:
        building: The building to navigate
        include_business: Whether to include business name on packages
        delivery_counter: Counter for document_id
        max_steps: Maximum steps per delivery (None = no limit)
        sync_storage: If True, wait for memory storage to complete (slower but accurate timing)

    Returns:
        dict with keys: success, steps, llm_times, package_str, error, injection_count (if any)
    """
    from building import AgentState

    package = building.generate_package(include_business=include_business)
    memory.set_document_id(f"delivery-{delivery_counter}")

    # Use consistent setup with UI mode
    agent_state = AgentState()
    agent_state.current_package = package

    # Use same simple system prompt as UI mode
    messages = [
        {"role": "system", "content": "You are a delivery agent. Use the tools provided to get it delivered."},
        {"role": "user", "content": f"Please deliver this package: {package}"}
    ]

    tools = AgentTools(building, agent_state)
    llm_times = []
    success = False
    error = None
    injection_count = 0  # Track total memories injected

    # Use model from environment (consistent with UI mode)
    model = os.environ.get("LLM_MODEL", "openai/gpt-4o-mini")

    while max_steps is None or agent_state.steps_taken < max_steps:
        try:
            step_num = len(llm_times) + 1
            print(f"[FF] Delivery #{delivery_counter} step {step_num}: calling LLM...", flush=True)

            t0 = time.time()
            response = memory.completion(
                model=model,
                messages=messages,
                tools=TOOL_DEFINITIONS,
                tool_choice="required",
                timeout=30
            )
            t1 = time.time()
            llm_times.append(t1 - t0)

            # Track memory injection (first call only typically has injection)
            try:
                injection_debug = hindsight_litellm.get_last_injection_debug()
                if injection_debug and injection_debug.injected:
                    injection_count = injection_debug.results_count or 0
            except Exception:
                pass

            message = response.choices[0].message

            # Log tool calls
            if message.tool_calls:
                tool_names = [tc.function.name for tc in message.tool_calls]
                print(f"[FF] Delivery #{delivery_counter} step {step_num}: {', '.join(tool_names)} ({t1-t0:.2f}s)", flush=True)

            if message.tool_calls:
                tool_results = []
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}
                    result = execute_tool(tools, tool_name, arguments)

                    tool_results.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "content": result
                    })

                    # Check for success
                    if "SUCCESS!" in result:
                        success = True
                        break

                # Update messages (serialize tool_calls for JSON compatibility)
                serialized_tool_calls = [
                    {"id": tc.id, "type": "function", "function": {"name": tc.function.name, "arguments": tc.function.arguments}}
                    for tc in message.tool_calls
                ] if message.tool_calls else []
                messages.append({"role": "assistant", "content": message.content, "tool_calls": serialized_tool_calls})
                messages.extend(tool_results)

                if success:
                    # Store final conversation
                    print(f"[FF] Delivery #{delivery_counter} SUCCESS in {agent_state.steps_taken} steps!", flush=True)
                    final_convo = _format_messages_for_retain(messages)
                    memory.retain(final_convo, sync=sync_storage)
                    break
            else:
                # No tool calls - nudge to use tools
                messages.append({"role": "assistant", "content": message.content})
                messages.append({"role": "user", "content": "Use the available tools to complete the delivery."})

        except Exception as e:
            error = str(e)
            break

    # Check for storage errors (from auto-storage after completion)
    storage_errors = memory.get_pending_storage_errors()
    storage_error_msgs = []
    if storage_errors:
        for err in storage_errors:
            print(f"[STORAGE ERROR] {err}", flush=True)
            storage_error_msgs.append(str(err))

    # Check for retain errors (from manual async retain calls)
    retain_errors = memory.get_pending_retain_errors()
    retain_error_msgs = []
    if retain_errors:
        for err in retain_errors:
            print(f"[RETAIN ERROR] {err}", flush=True)
            retain_error_msgs.append(str(err))

    # Determine if we hit the step limit
    hit_step_limit = max_steps is not None and agent_state.steps_taken >= max_steps and not success

    return {
        "success": success,
        "steps": agent_state.steps_taken,
        "llm_times": llm_times,
        "package_str": str(package),
        "error": error,
        "storage_errors": storage_error_msgs,
        "retain_errors": retain_error_msgs,
        "hit_step_limit": hit_step_limit,
        "injection_count": injection_count,  # Memory injection count
    }


def _run_single_delivery_eval(
    building,
    delivery_id: int,
    max_steps: int = 50,
    config: EvalConfig = EvalConfig.RECALL_MID,
) -> DeliveryData:
    """Run a single delivery with detailed data collection for evaluation.

    This captures all the data needed for analysis:
    - Every step's tool calls and results
    - Memory injection details
    - Error categorization
    - Timing information

    Args:
        building: The building to navigate
        delivery_id: Unique ID for this delivery
        max_steps: Maximum steps allowed
        config: Hindsight configuration to use

    Returns:
        DeliveryData with complete step-by-step information
    """
    from building import AgentState

    # Generate package
    package = building.generate_package(include_business=False)
    memory.set_document_id(f"eval-delivery-{delivery_id}")

    # Compute optimal path
    optimal_info = compute_optimal_path(building, package)
    optimal_steps = optimal_info.get("optimal_steps", 0)
    target_floor = optimal_info.get("target_floor", 1)
    target_side = optimal_info.get("target_side", Side.FRONT)

    # Get employee's business for relevance checking
    emp_info = building.find_employee(package.recipient_name)
    target_business = emp_info[0].name if emp_info else None

    # Setup agent state
    agent_state = AgentState()
    agent_state.current_package = package

    messages = [
        {"role": "system", "content": "You are a delivery agent. Use the tools provided to get it delivered."},
        {"role": "user", "content": f"Please deliver this package: {package}"}
    ]

    tools = AgentTools(building, agent_state)
    model = os.environ.get("LLM_MODEL", "openai/gpt-4o-mini")

    # Data collection
    steps_data = []
    llm_times = []
    success = False
    error = None
    failure_reason = None
    total_memories_injected = 0
    relevant_memories_count = 0

    delivery_start = time.time()

    step_num = 0
    while step_num < max_steps:
        step_num += 1

        try:
            t0 = time.time()
            response = memory.completion(
                model=model,
                messages=messages,
                tools=TOOL_DEFINITIONS,
                tool_choice="required",
                timeout=30
            )
            t1 = time.time()
            llm_time_ms = (t1 - t0) * 1000
            llm_times.append(llm_time_ms)

            # Capture memory injection info
            memory_injection = None
            try:
                injection_debug = hindsight_litellm.get_last_injection_debug()
                if injection_debug and injection_debug.injected:
                    memories_list = []

                    # Extract memories from recall results (handle both dict and object types)
                    if injection_debug.recall_results:
                        for r in injection_debug.recall_results:
                            if isinstance(r, dict):
                                memories_list.append(r.get("text", str(r)))
                            elif hasattr(r, "text"):
                                memories_list.append(r.text)
                            else:
                                memories_list.append(str(r))
                    elif injection_debug.reflect_text:
                        memories_list = [injection_debug.reflect_text]
                    elif injection_debug.memory_context:
                        # Fallback to the formatted memory context
                        memories_list = [injection_debug.memory_context]

                    # Check relevance
                    relevance = check_memory_relevance(
                        memories_list,
                        package.recipient_name,
                        target_floor,
                        target_side,
                        target_business,
                    )

                    memory_injection = {
                        "mode": injection_debug.mode,
                        "count": injection_debug.results_count or len(memories_list),
                        "memories": memories_list[:5],  # Limit to first 5 for storage
                        "relevant": relevance["relevant_count"] > 0,
                        "relevant_count": relevance["relevant_count"],
                        "relevance_types": relevance["relevance_types"],
                    }

                    total_memories_injected += injection_debug.results_count or len(memories_list)
                    relevant_memories_count += relevance["relevant_count"]
            except Exception as e:
                # Log injection debug errors for troubleshooting
                print(f"[EVAL] Warning: Failed to capture injection debug: {e}", flush=True)

            message = response.choices[0].message

            if message.tool_calls:
                tool_calls_data = []
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}

                    # Capture floor/side BEFORE the tool call (for error categorization)
                    floor_before = agent_state.floor
                    side_before = agent_state.side

                    result = execute_tool(tools, tool_name, arguments)

                    tool_calls_data.append({
                        "name": tool_name,
                        "args": arguments,
                        "result": result,
                    })

                    # Check for errors using state BEFORE the move
                    error_type = categorize_error(
                        tool_name,
                        floor_before,
                        side_before,
                        target_floor,
                        target_side,
                        "SUCCESS!" in result,
                    )

                    # Record step data
                    step_data = StepData(
                        step_number=step_num,
                        tool_calls=tool_calls_data,
                        llm_time_ms=llm_time_ms,
                        memory_injection=memory_injection,
                        llm_response_content=message.content,
                        action_correct=error_type is None,
                        error_type=error_type,
                    )
                    steps_data.append(step_data)

                    if "SUCCESS!" in result:
                        success = True
                        break

                # Update messages
                serialized_tool_calls = [
                    {"id": tc.id, "type": "function", "function": {"name": tc.function.name, "arguments": tc.function.arguments}}
                    for tc in message.tool_calls
                ] if message.tool_calls else []
                messages.append({"role": "assistant", "content": message.content, "tool_calls": serialized_tool_calls})

                tool_results = []
                for i, tool_call in enumerate(message.tool_calls):
                    tool_results.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "content": tool_calls_data[i]["result"] if i < len(tool_calls_data) else ""
                    })
                messages.extend(tool_results)

                if success:
                    break
            else:
                # No tool calls - nudge
                messages.append({"role": "assistant", "content": message.content})
                messages.append({"role": "user", "content": "Use the available tools to complete the delivery."})

        except Exception as e:
            error = str(e)
            failure_reason = f"Exception: {error}"
            break

    # Check if hit step limit
    if not success and step_num >= max_steps:
        failure_reason = f"Exceeded {max_steps} step limit"

    # Store ALL deliveries (success AND failures) - failures contain learning info too
    # e.g., "I tried floor 3 but John wasn't there" helps learn where John IS
    try:
        final_convo = _format_messages_for_retain(messages)
        outcome = "SUCCESS" if success else f"FAILED: {failure_reason or 'unknown'}"
        content_to_store = f"Delivery attempt for {package.recipient_name}:\n{outcome}\n\n{final_convo}"
        memory.retain(content_to_store, sync=True)  # Sync for evaluation accuracy
    except Exception as e:
        print(f"[EVAL] Warning: Failed to store delivery {delivery_id}: {e}", flush=True)

    delivery_time = time.time() - delivery_start

    return DeliveryData(
        delivery_id=delivery_id,
        package={
            "recipient": package.recipient_name,
            "business": package.business_name,
            "floor": target_floor,
            "side": target_side.value,
        },
        optimal_steps=optimal_steps,
        success=success,
        actual_steps=step_num,
        total_time_ms=delivery_time * 1000,
        llm_time_ms=sum(llm_times),
        steps=steps_data,
        failure_reason=failure_reason,
        memories_injected_total=total_memories_injected,
        relevant_memories_count=relevant_memories_count,
    )


def _run_evaluation(
    building,
    config: EvalConfig,
    num_deliveries: int,
    max_steps: int,
    progress_callback=None,
) -> tuple[str, list[DeliveryData]]:
    """Run a complete evaluation with the given configuration.

    Args:
        building: The building to use
        config: Hindsight configuration
        num_deliveries: Number of deliveries to run
        max_steps: Max steps per delivery
        progress_callback: Function to call with (current, total) for progress updates

    Returns:
        Tuple of (run_directory_path, list of DeliveryData)
    """
    # Get settings for this config
    settings = EVAL_CONFIG_SETTINGS[config]

    # Configure hindsight with these settings
    hindsight_litellm.configure(
        hindsight_api_url=os.environ.get("HINDSIGHT_API_URL", "http://localhost:8888"),
        store_conversations=False,  # We explicitly retain at end of each delivery
        inject_memories=settings["inject_memories"],
        verbose=True,  # Required to get injection debug info for analysis
    )

    # Create unique bank for this evaluation run
    eval_bank_id = f"eval-{config.value}-{uuid.uuid4().hex[:8]}"
    hindsight_litellm.set_defaults(
        bank_id=eval_bank_id,
        use_reflect=settings["use_reflect"],
        recall_budget=settings["recall_budget"],
    )

    if settings["inject_memories"]:
        hindsight_litellm.enable()

    # Setup evaluation runner
    runner = EvaluationRunner()
    run_dir = runner.create_run_directory(config)

    # Save config (include bank_id for reference)
    settings_with_bank = {**settings, "bank_id": eval_bank_id}
    runner.save_config(run_dir, config, settings_with_bank, building, num_deliveries)

    # Run deliveries
    deliveries = []
    start_time = time.time()

    for i in range(num_deliveries):
        delivery_id = i + 1

        if progress_callback:
            progress_callback(delivery_id, num_deliveries)

        print(f"[EVAL] {config.value} - Delivery {delivery_id}/{num_deliveries}", flush=True)

        delivery_data = _run_single_delivery_eval(
            building=building,
            delivery_id=delivery_id,
            max_steps=max_steps,
            config=config,
        )
        deliveries.append(delivery_data)

        # Save delivery data incrementally
        runner.save_delivery(run_dir, delivery_data)

    total_time = time.time() - start_time

    # Disable hindsight if it was enabled
    if settings["inject_memories"]:
        hindsight_litellm.disable()

    # Generate and save summary
    summary = generate_summary(config, deliveries, total_time, building)
    runner.save_summary(run_dir, summary)

    # Generate and save report
    timestamp = os.path.basename(run_dir).replace(f"run_", "").replace(f"_{config.value}", "")
    report = generate_report_markdown(config, summary, building, settings, timestamp)
    runner.save_report(run_dir, report)

    print(f"[EVAL] {config.value} complete! Results saved to: {run_dir}", flush=True)

    return run_dir, deliveries


@st.dialog("Select Recipient", width="large")
def recipient_dialog(building, include_business):
    """Dialog to select a recipient from the building directory."""

    st.markdown("**Select a recipient for delivery:**")

    # Build list of all employees grouped by floor
    all_options = []
    employee_map = {}  # Maps display string to (emp_name, business_name)

    floors_data = building.get_floor_display()

    for floor_data in floors_data:
        floor_num = floor_data["floor"]
        front_biz = floor_data["front"]
        back_biz = floor_data["back"]

        if front_biz:
            for emp in front_biz.employees:
                label = f"F{floor_num} | {front_biz.name} | {emp.name}"
                all_options.append(label)
                employee_map[label] = (emp.name, front_biz.name)

        if back_biz:
            for emp in back_biz.employees:
                label = f"F{floor_num} | {back_biz.name} | {emp.name}"
                all_options.append(label)
                employee_map[label] = (emp.name, back_biz.name)

    # Selectbox for choosing recipient
    selected = st.selectbox(
        "Choose recipient:",
        options=all_options,
        index=None,
        placeholder="Select a person..."
    )

    # Confirm button
    if st.button("âœ… Confirm & Start Delivery", use_container_width=True, type="primary", disabled=selected is None):
        if selected:
            emp_name, business_name = employee_map[selected]
            st.session_state.selected_recipient = emp_name
            st.session_state.selected_business = business_name if include_business else None
            st.session_state.start_delivery_now = True
            st.session_state.show_recipient_dialog = False
            st.rerun()


def main():
    # Track if UI needs refresh (set in UI tab, checked at end of function)
    needs_refresh = False

    # Title
    st.markdown("""
    <h1 style="text-align: center; color: #00ff00; font-family: monospace;">
        ðŸ“¦ DELIVERY AGENT DEMO ðŸ“¦
    </h1>
    <p style="text-align: center; color: #888888;">
        Watch an AI agent learn to navigate a building using Hindsight memory
    </p>
    """, unsafe_allow_html=True)

    # Difficulty selector - single click switches and resets
    if "difficulty" not in st.session_state:
        st.session_state.difficulty = "easy"

    difficulty_options = {
        "easy": "ðŸŸ¢ Easy - Simple Office",
        "medium": "ðŸŸ¡ Medium - Industrial Building",
        "hard": "ðŸ”´ Hard - Space Station"
    }

    col_diff, col_desc = st.columns([1, 2])
    with col_diff:
        new_difficulty = st.radio(
            "Difficulty",
            options=list(difficulty_options.keys()),
            format_func=lambda x: difficulty_options[x],
            index=list(difficulty_options.keys()).index(st.session_state.difficulty),
            horizontal=True,
            label_visibility="collapsed"
        )

    # If difficulty changed, reset everything with new bank ID
    if new_difficulty != st.session_state.difficulty:
        st.session_state.difficulty = new_difficulty
        # Reset all state for fresh start
        st.session_state.current_actions = []
        st.session_state.action_queue = []
        st.session_state.displayed_actions = []
        st.session_state.last_display_time = 0
        st.session_state.delivery_complete_pending = False
        st.session_state.pending_delivery = None
        st.session_state.llm_messages = []
        st.session_state.stored_memories = []
        st.session_state.deliveries_completed = 0
        st.session_state.delivery_counter = 0
        st.session_state.loop_remaining = 0
        st.session_state.total_steps = 0
        st.session_state.delivery_history = []
        st.session_state.agent_floor = 1
        st.session_state.agent_side = "front"
        st.session_state.prev_agent_floor = 1
        st.session_state.prev_agent_side = "front"
        st.session_state.has_package = False
        st.session_state.current_action = None
        # New bank ID for this difficulty (memories don't overlap)
        st.session_state.session_id = f"{new_difficulty}-{uuid.uuid4().hex[:6]}"
        bank_id = memory.configure_memory(session_id=st.session_state.session_id)
        st.session_state.bank_id = bank_id
        st.rerun()

    with col_desc:
        desc_map = {
            "easy": "Left/right offices, single elevator",
            "medium": "Ladders skip floors (1â†’3, 3â†’5)",
            "hard": "Gravity lifts, teleporters, multiple routes"
        }
        st.caption(desc_map[st.session_state.difficulty])

    st.divider()

    # Initialize session state
    if "session_id" not in st.session_state:
        st.session_state.session_id = uuid.uuid4().hex[:8]
        # Configure memory with unique session ID
        bank_id = memory.configure_memory(session_id=st.session_state.session_id)
        st.session_state.bank_id = bank_id

    if "building" not in st.session_state:
        st.session_state.building = get_building()

    if "llm_messages" not in st.session_state:
        st.session_state.llm_messages = []  # Track LLM prompt/response for display

    if "stored_memories" not in st.session_state:
        st.session_state.stored_memories = []  # Track memories stored this session

    if "deliveries_completed" not in st.session_state:
        st.session_state.deliveries_completed = 0

    if "delivery_counter" not in st.session_state:
        st.session_state.delivery_counter = 0  # Increments at start of each delivery

    if "total_steps" not in st.session_state:
        st.session_state.total_steps = 0

    if "delivery_history" not in st.session_state:
        st.session_state.delivery_history = []

    if "current_actions" not in st.session_state:
        st.session_state.current_actions = []

    # Queue-based animation system
    if "action_queue" not in st.session_state:
        st.session_state.action_queue = []  # Actions waiting to be displayed

    if "displayed_actions" not in st.session_state:
        st.session_state.displayed_actions = []  # Actions already shown

    if "last_display_time" not in st.session_state:
        st.session_state.last_display_time = 0  # Timestamp of last displayed action

    if "animation_duration" not in st.session_state:
        st.session_state.animation_duration = 1.5  # Seconds per animation

    if "delivery_complete_pending" not in st.session_state:
        st.session_state.delivery_complete_pending = False  # Delivery done but animations pending

    if "agent_floor" not in st.session_state:
        st.session_state.agent_floor = 1

    if "agent_side" not in st.session_state:
        st.session_state.agent_side = "front"

    if "prev_agent_floor" not in st.session_state:
        st.session_state.prev_agent_floor = 1

    if "prev_agent_side" not in st.session_state:
        st.session_state.prev_agent_side = "front"

    if "has_package" not in st.session_state:
        st.session_state.has_package = False

    if "is_running" not in st.session_state:
        st.session_state.is_running = False

    if "last_package_info" not in st.session_state:
        st.session_state.last_package_info = None

    if "step_by_step" not in st.session_state:
        st.session_state.step_by_step = False

    if "pending_delivery" not in st.session_state:
        st.session_state.pending_delivery = None

    if "delivery_generator" not in st.session_state:
        st.session_state.delivery_generator = None

    if "current_result" not in st.session_state:
        st.session_state.current_result = None

    if "current_action" not in st.session_state:
        st.session_state.current_action = None

    if "show_recipient_dialog" not in st.session_state:
        st.session_state.show_recipient_dialog = False

    if "selected_recipient" not in st.session_state:
        st.session_state.selected_recipient = None

    if "selected_business" not in st.session_state:
        st.session_state.selected_business = None

    if "start_delivery_now" not in st.session_state:
        st.session_state.start_delivery_now = False

    if "include_business" not in st.session_state:
        st.session_state.include_business = False

    if "max_steps_per_delivery" not in st.session_state:
        st.session_state.max_steps_per_delivery = None  # None = no limit

    if "ff_errors" not in st.session_state:
        st.session_state.ff_errors = []  # Track errors during FF mode

    # Background thread state for UI mode streaming
    # Note: The actual queue.Queue object is stored in _GLOBAL_QUEUES, not session state
    # This is because queue.Queue objects don't survive Streamlit hot-reloads
    if "bg_queue_active" not in st.session_state:
        st.session_state.bg_queue_active = False  # Whether there's an active queue for this session

    if "bg_delivery_running" not in st.session_state:
        st.session_state.bg_delivery_running = False

    if "bg_delivery_complete_info" not in st.session_state:
        st.session_state.bg_delivery_complete_info = None  # Completion info from thread

    building = st.session_state.building

    # Auto-start delivery if recipient was selected (check this FIRST)
    if st.session_state.start_delivery_now and st.session_state.selected_recipient:
        st.session_state.start_delivery_now = False
        st.session_state.show_recipient_dialog = False  # Ensure dialog is closed
        st.session_state.current_actions = []
        st.session_state.action_queue = []  # Reset action queue
        st.session_state.displayed_actions = []
        st.session_state.llm_messages = []
        st.session_state.has_package = True
        st.session_state.agent_floor = 1
        st.session_state.agent_side = "front"
        st.session_state.prev_agent_floor = 1
        st.session_state.prev_agent_side = "front"
        st.session_state.current_action = None
        st.session_state.delivery_start_time = time.time()
        st.session_state.delivery_complete_pending = False
        st.session_state.bg_delivery_complete_info = None  # Clear any previous completion
        # Clear old queue before creating new one - process any pending complete
        complete_item = _clear_queue(st.session_state.session_id)
        _process_complete_item(complete_item)
        st.session_state.bg_queue_active = False

        # Create package for selected recipient
        recipient_name = st.session_state.selected_recipient
        business_info = building.find_employee(recipient_name)
        business_name = business_info[0].name if business_info and st.session_state.include_business else None
        package = Package(
            id=f"{random.randint(1000, 9999)}",
            recipient_name=recipient_name,
            business_name=business_name
        )
        st.session_state.last_package_info = str(package)

        # Increment delivery counter and set document_id for memory grouping
        st.session_state.delivery_counter += 1
        memory.set_document_id(f"delivery-{st.session_state.delivery_counter}")

        # Get model from a temp agent
        model = os.environ.get("LLM_MODEL", "openai/gpt-4o-mini")

        # Start background thread for delivery using global queue storage
        action_q = _get_or_create_queue(st.session_state.session_id)
        cancel_evt = _get_or_create_cancel_event(st.session_state.session_id)
        _reset_cancel_event(st.session_state.session_id)  # Clear any previous cancellation
        st.session_state.bg_queue_active = True
        st.session_state.bg_delivery_running = True
        st.session_state.bg_delivery_complete_info = None

        _debug_log(f"Starting delivery thread for {package}")

        thread = threading.Thread(
            target=_run_delivery_in_background,
            args=(action_q, building, package, model, st.session_state.max_steps_per_delivery, cancel_evt),
            daemon=True
        )
        thread.start()

        # Clear selected recipient
        st.session_state.selected_recipient = None
        st.session_state.selected_business = None
        st.rerun()

    # Show recipient dialog if triggered (after checking for delivery start)
    if st.session_state.show_recipient_dialog:
        recipient_dialog(building, st.session_state.include_business)

    # Initialize timing state
    if "loop_remaining" not in st.session_state:
        st.session_state.loop_remaining = 0
    if "timing_llm_calls" not in st.session_state:
        st.session_state.timing_llm_calls = []
    if "timing_deliveries" not in st.session_state:
        st.session_state.timing_deliveries = []
    if "timing_loop_start" not in st.session_state:
        st.session_state.timing_loop_start = None
    if "delivery_start_time" not in st.session_state:
        st.session_state.delivery_start_time = None

    # Mode tabs at top
    ui_tab, ff_tab, eval_tab = st.tabs(["ðŸŽ® UI Mode", "âš¡ Fast-Forward Mode", "ðŸ“Š Evaluation Mode"])

    with ff_tab:
        # Fast-forward mode - minimal UI for benchmarking
        st.markdown("### âš¡ Fast-Forward Mode")
        st.caption("Maximum speed - no animations, minimal UI")

        # Memory Bank ID display with copy button (compact)
        bank_id = st.session_state.get('bank_id', 'N/A')
        bank_col1, bank_col2 = st.columns([2, 3])
        with bank_col1:
            st.markdown("ðŸ¦ **Memory Bank:**")
        with bank_col2:
            st.code(bank_id, language=None)

        col_ff_controls, col_ff_stats = st.columns([1, 1])

        with col_ff_controls:
            loop_count = st.slider("Deliveries to run", min_value=1, max_value=100, value=10, key="ff_loop_count")

            # Max steps per delivery - number input, empty = no limit
            max_steps_input = st.number_input(
                "Max steps per delivery",
                min_value=1,
                max_value=500,
                value=None,
                placeholder="No limit",
                help="Leave empty for no limit. Delivery fails if it exceeds this many steps.",
                key="ff_max_steps"
            )
            st.session_state.max_steps_per_delivery = max_steps_input

            # Include business checkbox (shared with UI mode)
            include_business_ff = st.checkbox(
                "Include business name",
                value=st.session_state.include_business,
                help="If checked, package will show the business name",
                key="ff_include_business"
            )
            st.session_state.include_business = include_business_ff

            # Sync storage option (FF mode only)
            # Note: Don't set session_state after widget - key auto-stores the value
            st.checkbox(
                "Sync storage",
                value=st.session_state.get("ff_sync_storage", False),
                help="If checked, wait for memory storage to complete before timing. Slower but more accurate benchmarks.",
                key="ff_sync_storage"
            )

            is_running = st.session_state.loop_remaining > 0
            if st.button("ðŸš€ Run Loop", use_container_width=True, disabled=is_running, key="ff_loop_btn"):
                st.session_state.fast_forward = True
                st.session_state.loop_remaining = loop_count
                st.session_state.timing_loop_start = time.time()
                st.session_state.timing_llm_calls = []
                st.session_state.timing_deliveries = []
                st.session_state.ff_errors = []  # Clear errors for new run
                st.session_state.ff_injection_counts = []  # Track injection counts

            if st.button("ðŸ“¦ Single Delivery", use_container_width=True, disabled=is_running, key="ff_single_btn"):
                st.session_state.fast_forward = True
                st.session_state.loop_remaining = 1
                st.session_state.ff_errors = []
                st.session_state.ff_injection_counts = []

            if st.button("ðŸ›‘ Stop", use_container_width=True, disabled=not is_running, key="ff_stop_btn"):
                st.session_state.loop_remaining = 0
                st.session_state.fast_forward = False

            # Reset buttons
            st.markdown("---")
            col_reset1, col_reset2 = st.columns(2)
            with col_reset1:
                if st.button("ðŸ”„ Full Reset", use_container_width=True, disabled=is_running, key="ff_full_reset"):
                    # Reset all state
                    st.session_state.session_id = uuid.uuid4().hex[:8]
                    bank_id = memory.configure_memory(session_id=st.session_state.session_id)
                    st.session_state.bank_id = bank_id
                    st.session_state.deliveries_completed = 0
                    st.session_state.delivery_counter = 0
                    st.session_state.total_steps = 0
                    st.session_state.delivery_history = []
                    st.session_state.timing_llm_calls = []
                    st.session_state.timing_deliveries = []
                    st.session_state.timing_loop_start = None
                    st.session_state.ff_errors = []
                    st.session_state.ff_injection_counts = []
                    st.session_state.loop_remaining = 0
                    st.session_state.fast_forward = False
                    st.rerun()
            with col_reset2:
                if st.button("ðŸ§¹ Clear Memory", use_container_width=True, disabled=is_running, key="ff_clear_mem"):
                    # New bank but keep timing stats
                    st.session_state.session_id = uuid.uuid4().hex[:8]
                    bank_id = memory.configure_memory(session_id=st.session_state.session_id)
                    st.session_state.bank_id = bank_id
                    st.session_state.deliveries_completed = 0
                    st.session_state.delivery_counter = 0
                    st.session_state.total_steps = 0
                    st.session_state.delivery_history = []
                    st.session_state.ff_injection_counts = []
                    st.rerun()

        with col_ff_stats:
            st.markdown("#### â±ï¸ Benchmarks")
            llm_times = st.session_state.timing_llm_calls
            delivery_times = st.session_state.timing_deliveries
            injection_counts = st.session_state.get("ff_injection_counts", [])

            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("Deliveries", len(delivery_times))
                if llm_times:
                    st.metric("Avg LLM", f"{sum(llm_times)/len(llm_times):.2f}s")
            with col_b:
                st.metric("LLM Calls", len(llm_times))
                if delivery_times:
                    st.metric("Avg Delivery", f"{sum(delivery_times)/len(delivery_times):.1f}s")

            if st.session_state.timing_loop_start and delivery_times:
                total = time.time() - st.session_state.timing_loop_start
                st.metric("Total Time", f"{total:.1f}s")

            # Memory injection stats
            if injection_counts:
                st.markdown("#### ðŸ§  Memory")
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    injected_count = sum(1 for c in injection_counts if c > 0)
                    st.metric("With Memories", f"{injected_count}/{len(injection_counts)}")
                with col_m2:
                    if any(c > 0 for c in injection_counts):
                        avg_inj = sum(injection_counts) / max(1, injected_count)
                        st.metric("Avg Injected", f"{avg_inj:.0f}")

        # Show errors from FF runs
        if st.session_state.ff_errors:
            with st.expander(f"âš ï¸ Errors ({len(st.session_state.ff_errors)})", expanded=False):
                # Show all errors in scrollable container
                error_container = st.container(height=300)
                with error_container:
                    for err in st.session_state.ff_errors:
                        st.error(err)

        # Learning curve in fast-forward
        if len(st.session_state.delivery_history) >= 1:
            st.markdown("### ðŸ“ˆ Learning Curve")
            steps_history = [d["steps"] for d in st.session_state.delivery_history]
            df = pd.DataFrame({
                "Delivery": range(1, len(steps_history) + 1),
                "Steps": steps_history
            })
            st.line_chart(df, x="Delivery", y="Steps", use_container_width=True)

        # Fast-forward delivery loop - uses st.empty() for real-time updates
        if st.session_state.get("fast_forward", False) and st.session_state.loop_remaining > 0:
            # Create placeholders for real-time updates
            progress_placeholder = st.empty()
            status_placeholder = st.empty()

            total_to_run = st.session_state.loop_remaining
            completed_this_run = 0

            # Run ALL deliveries in a single loop without st.rerun()
            while st.session_state.loop_remaining > 0:
                st.session_state.loop_remaining -= 1
                st.session_state.delivery_counter += 1
                completed_this_run += 1

                # Update progress in real-time
                progress = completed_this_run / total_to_run
                progress_placeholder.progress(progress, text=f"Delivery {completed_this_run}/{total_to_run}")
                status_placeholder.info(f"ðŸš€ Running delivery {completed_this_run}...")

                delivery_start = time.time()

                # Run entire delivery
                result = _run_single_delivery_ff(
                    building=building,
                    include_business=st.session_state.include_business,
                    delivery_counter=st.session_state.delivery_counter,
                    max_steps=st.session_state.max_steps_per_delivery,
                    sync_storage=st.session_state.get("ff_sync_storage", False),
                )

                delivery_time = time.time() - delivery_start

                # Update stats
                st.session_state.timing_llm_calls.extend(result["llm_times"])
                st.session_state.timing_deliveries.append(delivery_time)
                st.session_state.total_steps += result["steps"]
                if result["success"]:
                    st.session_state.deliveries_completed += 1
                st.session_state.delivery_history.append({
                    "package": result["package_str"],
                    "success": result["success"],
                    "steps": result["steps"],
                })
                st.session_state.last_package_info = result["package_str"]

                # Track memory injection counts
                if "ff_injection_counts" not in st.session_state:
                    st.session_state.ff_injection_counts = []
                st.session_state.ff_injection_counts.append(result.get("injection_count", 0))

                # Track errors for UI display
                delivery_num = st.session_state.delivery_counter
                steps = result["steps"]

                if result["error"]:
                    err_msg = f"Delivery #{delivery_num} (step {steps}): {result['error']}"
                    st.session_state.ff_errors.append(err_msg)
                    print(f"[FF ERROR] {err_msg}", flush=True)

                if result["storage_errors"]:
                    for se in result["storage_errors"]:
                        err_msg = f"Delivery #{delivery_num} (step {steps}) storage error: {se}"
                        st.session_state.ff_errors.append(err_msg)

                if result.get("retain_errors"):
                    for re in result["retain_errors"]:
                        err_msg = f"Delivery #{delivery_num} (step {steps}) retain error: {re}"
                        st.session_state.ff_errors.append(err_msg)
                        print(f"[FF RETAIN ERROR] {err_msg}", flush=True)

                if result["hit_step_limit"]:
                    err_msg = f"Delivery #{delivery_num}: Hit step limit ({st.session_state.max_steps_per_delivery} steps)"
                    st.session_state.ff_errors.append(err_msg)
                    print(f"[FF STEP LIMIT] {err_msg}", flush=True)

            # Clear placeholders and show completion
            progress_placeholder.empty()
            status_placeholder.success(f"âœ… Completed {completed_this_run} deliveries!")

            # Clear fast_forward flag and rerun once to update all stats
            st.session_state.fast_forward = False
            time.sleep(0.5)  # Brief pause to show success message
            st.rerun()

    with eval_tab:
        # Evaluation Mode - systematic testing with different Hindsight configurations
        st.markdown("### ðŸ“Š Evaluation Mode")
        st.caption("Run systematic evaluations with different Hindsight configurations")

        # Initialize evaluation state
        if "eval_running" not in st.session_state:
            st.session_state.eval_running = False
        if "eval_results" not in st.session_state:
            st.session_state.eval_results = []

        col_eval_config, col_eval_results = st.columns([1, 1])

        with col_eval_config:
            st.markdown("#### Configuration")

            # Number of deliveries per config
            num_deliveries = st.slider(
                "Deliveries per configuration",
                min_value=5,
                max_value=1000,
                value=100,
                step=5,
                key="eval_num_deliveries",
                help="Number of deliveries to run for each selected configuration"
            )

            # Max steps per delivery
            eval_max_steps = st.number_input(
                "Max steps per delivery",
                min_value=10,
                max_value=500,
                value=150,
                key="eval_max_steps",
                help="Maximum steps allowed before a delivery is considered failed. Higher values allow more exploration early on before memories accumulate."
            )

            st.markdown("#### Select Configurations")
            st.caption("Choose which Hindsight configurations to test:")

            # Configuration selection with descriptions
            config_options = {
                EvalConfig.BASELINE: "ðŸš« Baseline (No Memory)",
                EvalConfig.RECALL_LOW: "ðŸ“¥ Recall - Low Budget",
                EvalConfig.RECALL_MID: "ðŸ“¥ Recall - Mid Budget",
                EvalConfig.RECALL_HIGH: "ðŸ“¥ Recall - High Budget",
                EvalConfig.REFLECT_LOW: "ðŸªž Reflect - Low Budget",
                EvalConfig.REFLECT_MID: "ðŸªž Reflect - Mid Budget",
                EvalConfig.REFLECT_HIGH: "ðŸªž Reflect - High Budget",
            }

            selected_configs = []
            for config, label in config_options.items():
                if st.checkbox(label, value=config in [EvalConfig.BASELINE, EvalConfig.RECALL_MID], key=f"eval_config_{config.value}"):
                    selected_configs.append(config)

            # Estimate
            if selected_configs:
                total_deliveries = len(selected_configs) * num_deliveries
                st.info(f"ðŸ“Š Will run **{total_deliveries}** total deliveries ({len(selected_configs)} configs Ã— {num_deliveries} each)")

                # Disk space estimate
                est_size_mb = total_deliveries * 0.03  # ~30KB per delivery
                st.caption(f"Estimated disk usage: ~{est_size_mb:.1f} MB")

            # Run button
            st.markdown("---")
            is_eval_running = st.session_state.eval_running

            if st.button(
                "ðŸš€ Start Evaluation",
                use_container_width=True,
                disabled=is_eval_running or len(selected_configs) == 0,
                type="primary",
                key="eval_start_btn"
            ):
                st.session_state.eval_running = True
                st.session_state.eval_results = []
                st.rerun()

            if st.button(
                "ðŸ›‘ Stop",
                use_container_width=True,
                disabled=not is_eval_running,
                key="eval_stop_btn"
            ):
                st.session_state.eval_running = False
                st.rerun()

        with col_eval_results:
            st.markdown("#### Results")

            # Show progress if running
            if st.session_state.eval_running and selected_configs:
                progress_placeholder = st.empty()
                status_placeholder = st.empty()
                results_placeholder = st.empty()

                total_configs = len(selected_configs)
                completed_configs = 0

                for config in selected_configs:
                    if not st.session_state.eval_running:
                        break  # Stop if user clicked stop

                    status_placeholder.info(f"ðŸ”„ Running: **{config.value}** ({completed_configs + 1}/{total_configs})")

                    def update_progress(current, total):
                        progress = (completed_configs * num_deliveries + current) / (total_configs * num_deliveries)
                        progress_placeholder.progress(progress, text=f"Config {completed_configs + 1}/{total_configs}: Delivery {current}/{total}")

                    try:
                        run_dir, deliveries = _run_evaluation(
                            building=building,
                            config=config,
                            num_deliveries=num_deliveries,
                            max_steps=eval_max_steps,
                            progress_callback=update_progress,
                        )

                        # Load summary for display
                        summary_path = os.path.join(run_dir, "summary.json")
                        with open(summary_path) as f:
                            summary = json.load(f)

                        st.session_state.eval_results.append({
                            "config": config.value,
                            "run_dir": run_dir,
                            "summary": summary,
                        })

                        completed_configs += 1

                    except Exception as e:
                        st.error(f"Error running {config.value}: {e}")
                        print(f"[EVAL ERROR] {config.value}: {e}", flush=True)
                        import traceback
                        traceback.print_exc()

                # Done
                progress_placeholder.empty()
                status_placeholder.success(f"âœ… Completed {completed_configs}/{total_configs} configurations!")
                st.session_state.eval_running = False
                st.rerun()

            # Show completed results
            if st.session_state.eval_results:
                st.markdown("#### Completed Runs")

                # Summary comparison table
                comparison_data = []
                for result in st.session_state.eval_results:
                    summary = result["summary"]
                    comparison_data.append({
                        "Config": result["config"],
                        "Success Rate": f"{summary['success_rate']:.1%}",
                        "Avg Steps": f"{summary['avg_steps']:.1f}",
                        "Efficiency": f"{summary['step_efficiency']:.1%}",
                        "Deliveries": summary["total_deliveries"],
                    })

                if comparison_data:
                    st.dataframe(comparison_data, use_container_width=True)

                # Individual run details
                for result in st.session_state.eval_results:
                    summary = result["summary"]
                    with st.expander(f"ðŸ“ {result['config']}", expanded=False):
                        col_s1, col_s2, col_s3 = st.columns(3)
                        with col_s1:
                            st.metric("Success Rate", f"{summary['success_rate']:.1%}")
                        with col_s2:
                            st.metric("Avg Steps", f"{summary['avg_steps']:.1f}")
                        with col_s3:
                            st.metric("Efficiency", f"{summary['step_efficiency']:.1%}")

                        # Memory stats if available
                        mem_stats = summary.get("memory_stats", {})
                        if mem_stats.get("with_relevant_memory_count", 0) > 0:
                            st.markdown("**Memory Effectiveness:**")
                            col_m1, col_m2 = st.columns(2)
                            with col_m1:
                                st.metric(
                                    "With Relevant Memory",
                                    f"{mem_stats.get('with_relevant_memory_success_rate', 0):.1%}",
                                    help="Success rate when relevant memories were injected"
                                )
                            with col_m2:
                                st.metric(
                                    "Without Relevant Memory",
                                    f"{mem_stats.get('without_relevant_memory_success_rate', 0):.1%}",
                                    help="Success rate when no relevant memories were injected"
                                )

                        # Error breakdown
                        errors = summary.get("error_counts", {})
                        if errors:
                            st.markdown("**Error Breakdown:**")
                            for err_type, count in sorted(errors.items(), key=lambda x: -x[1])[:5]:
                                st.caption(f"â€¢ {err_type}: {count}")

                        # Link to files
                        st.caption(f"ðŸ“ Results saved to: `{result['run_dir']}`")

                # Clear results button
                if st.button("ðŸ—‘ï¸ Clear Results", key="eval_clear_results"):
                    st.session_state.eval_results = []
                    st.rerun()

            else:
                if not st.session_state.eval_running:
                    st.markdown("*No evaluation results yet. Select configurations and click Start.*")

        # Building layout reference
        st.markdown("---")
        st.markdown("#### ðŸ¢ Building Layout (Reference)")
        st.caption("All evaluations use this fixed building layout for consistency.")

        with st.expander("View Building Layout", expanded=False):
            layout = get_building_layout_dict(building)
            for floor_num in sorted(layout["floors"].keys(), reverse=True, key=int):
                floor_data = layout["floors"][floor_num]
                st.markdown(f"**Floor {floor_num}**")
                for side in ["front", "back"]:
                    if side in floor_data:
                        biz = floor_data[side]
                        employees = ", ".join([e["name"] for e in biz["employees"]])
                        st.caption(f"â€¢ {side.title()}: {biz['business_name']} - {employees}")

        # Previous runs
        st.markdown("---")
        st.markdown("#### ðŸ“‚ Previous Evaluation Runs")

        runner = EvaluationRunner()
        prev_runs = runner.get_all_runs()

        if prev_runs:
            for run in prev_runs[:10]:  # Show last 10
                run_name = run["name"]
                config = run.get("config", {})
                summary = run.get("summary", {})

                if summary:
                    with st.expander(f"ðŸ“ {run_name}", expanded=False):
                        col_p1, col_p2, col_p3 = st.columns(3)
                        with col_p1:
                            st.metric("Success Rate", f"{summary.get('success_rate', 0):.1%}")
                        with col_p2:
                            st.metric("Deliveries", summary.get("total_deliveries", 0))
                        with col_p3:
                            st.metric("Efficiency", f"{summary.get('step_efficiency', 0):.1%}")

                        st.caption(f"Config: {summary.get('config_name', 'N/A')}")
                        st.caption(f"Path: `{run['path']}`")

                        # View report button
                        report_path = os.path.join(run["path"], "report.md")
                        if os.path.exists(report_path):
                            with open(report_path) as f:
                                report_content = f.read()
                            st.markdown("**Report:**")
                            st.markdown(report_content)
        else:
            st.caption("*No previous evaluation runs found.*")

    with ui_tab:
        # Reset fast_forward when viewing UI tab
        st.session_state.fast_forward = False

        # Poll background queue BEFORE rendering columns so both see updated state
        # Get queue from cached storage (survives hot-reloads)
        bg_queue = _get_queue_storage().get(st.session_state.session_id)

        # SAFETY: If running but queue doesn't exist, reset the running flag
        # This can happen after cache clears or hot-reloads
        if st.session_state.bg_delivery_running and bg_queue is None and not st.session_state.action_queue:
            st.session_state.bg_delivery_running = False
            st.session_state.bg_queue_active = False

        if bg_queue is not None and (st.session_state.bg_delivery_running or st.session_state.action_queue or st.session_state.delivery_complete_pending):
            # Drain all available items from the thread-safe queue
            while True:
                try:
                    item = bg_queue.get_nowait()
                    item_type = item.get("type")

                    if item_type == "step":
                        # Combined step item - add to both action log and LLM messages
                        _debug_log(f"[QUEUE] Received step item: {item.get('step')}, tool={item.get('tool_name')}")
                        st.session_state.action_queue.append({
                            "step": item.get("step", "?"),
                            "tool_name": item["tool_name"],
                            "result": item["tool_result"],
                            "floor": item["floor"],
                            "side": item["side"],
                            "timing": item["timing"],
                            # Also include LLM info for expanded view
                            "prompt": item.get("prompt"),
                            "llm_response": item.get("llm_response"),
                        })
                        # Also add to llm_messages for the dedicated LLM section
                        st.session_state.llm_messages.append({
                            "step": item.get("step", "?"),
                            "prompt": item.get("prompt", {}),
                            "response": item.get("llm_response", {}),
                        })
                        _debug_log(f"[QUEUE] llm_messages now has {len(st.session_state.llm_messages)} items")
                    elif item_type == "action":
                        # Fallback for non-tool-call responses (nudge messages)
                        st.session_state.action_queue.append({
                            "step": item.get("step", "?"),
                            "tool_name": item["tool_name"],
                            "result": item["result"],
                            "floor": item["floor"],
                            "side": item["side"],
                            "timing": item["timing"],
                        })
                    elif item_type == "success":
                        st.session_state.delivery_complete_pending = True
                    elif item_type == "error":
                        st.session_state.action_queue.append({
                            "tool_name": "âŒ error",
                            "result": item["message"],
                            "floor": st.session_state.agent_floor,
                            "side": st.session_state.agent_side,
                            "timing": 0,
                        })
                        st.session_state.delivery_complete_pending = True
                    elif item_type == "step_limit":
                        st.session_state.action_queue.append({
                            "tool_name": "âš ï¸ step_limit",
                            "result": item["message"],
                            "floor": st.session_state.agent_floor,
                            "side": st.session_state.agent_side,
                            "timing": 0,
                        })
                        st.session_state.delivery_complete_pending = True
                    elif item_type == "cancelled":
                        st.session_state.action_queue.append({
                            "step": "â€”",
                            "tool_name": "ðŸ›‘ cancelled",
                            "result": item["message"],
                            "floor": st.session_state.agent_floor,
                            "side": st.session_state.agent_side,
                            "timing": 0,
                        })
                        st.session_state.delivery_complete_pending = True
                    elif item_type == "memory_storing":
                        st.session_state.action_queue.append({
                            "step": item.get("step", "?"),
                            "tool_name": "ðŸ§  storing_memory",
                            "result": "Storing delivery experience to Hindsight...",
                            "floor": st.session_state.agent_floor,
                            "side": st.session_state.agent_side,
                            "timing": 0,
                        })
                    elif item_type == "memory_stored":
                        st.session_state.action_queue.append({
                            "step": item.get("step", "?"),
                            "tool_name": "ðŸ§  memory_stored",
                            "result": f"Memory stored successfully!",
                            "floor": st.session_state.agent_floor,
                            "side": st.session_state.agent_side,
                            "timing": item.get("timing", 0),
                        })
                    elif item_type == "complete":
                        st.session_state.bg_delivery_complete_info = item
                        st.session_state.bg_delivery_running = False
                        # Don't count cancelled deliveries in stats/history
                        if not item.get("cancelled"):
                            st.session_state.total_steps += item["steps"]
                            if item["success"]:
                                st.session_state.deliveries_completed += 1
                            st.session_state.delivery_history.append({
                                "package": st.session_state.last_package_info,
                                "success": item["success"],
                                "steps": item["steps"],
                            })
                except queue.Empty:
                    break  # Queue empty
                except Exception as e:
                    _debug_log(f"[ERROR] Queue polling error: {e}\n{traceback.format_exc()}")
                    break

        # Process animation queue - advance one action per frame
        current_time = time.time()
        time_since_last = current_time - st.session_state.last_display_time
        should_advance = time_since_last >= st.session_state.animation_duration

        if st.session_state.step_by_step and st.session_state.action_queue:
            should_advance = False  # Will be set by Next Step button

        if st.session_state.action_queue and should_advance and not st.session_state.step_by_step:
            next_action = st.session_state.action_queue.pop(0)
            st.session_state.displayed_actions.append(next_action)
            st.session_state.last_display_time = current_time

            if next_action.get("floor") is not None:
                st.session_state.prev_agent_floor = st.session_state.agent_floor
                st.session_state.prev_agent_side = st.session_state.agent_side
                st.session_state.agent_floor = next_action["floor"]
                st.session_state.agent_side = next_action["side"]
                st.session_state.current_action = next_action["tool_name"]

        # Check if delivery complete and all animations done
        # Only finalize when we've received the "complete" item (bg_delivery_complete_info is set)
        # This prevents race condition where "success" arrives but "complete" hasn't yet
        if st.session_state.delivery_complete_pending and not st.session_state.action_queue and st.session_state.bg_delivery_complete_info:
            st.session_state.delivery_complete_pending = False
            _clear_queue(st.session_state.session_id)
            st.session_state.bg_queue_active = False
            st.session_state.has_package = False
            st.balloons()

        # Layout: Building and Action Log side by side at top
        col_building, col_log = st.columns([1, 1])

        with col_building:
            # Building visualization - Game View
            st.markdown("### ðŸŽ® Building View")

            # Show current package info prominently
            if st.session_state.last_package_info:
                st.info(f"ðŸ“¦ **Delivering:** {st.session_state.last_package_info}")
            elif st.session_state.bg_delivery_running:
                st.warning("ðŸ“¦ Package info loading...")

            # Get cached businesses dict for renderer
            businesses = building.get_businesses_for_renderer()

            game_html = generate_game_html(
                floor=st.session_state.agent_floor,
                side=st.session_state.agent_side,
                current_action=st.session_state.current_action,
                businesses=businesses,
                prev_floor=st.session_state.prev_agent_floor,
                prev_side=st.session_state.prev_agent_side,
                difficulty=st.session_state.difficulty,
            )
            components.html(game_html, height=600, scrolling=False)

        with col_log:
            # Action log (newest at top)
            st.markdown("### ðŸ“ Action Log")

            # Display actions
            if st.session_state.displayed_actions:
                log_container = st.container(height=600)
                with log_container:
                    # Display in reverse order (newest first)
                    for action_data in reversed(st.session_state.displayed_actions):
                        step = action_data.get("step", "?")
                        tool_name = action_data.get("tool_name", "unknown")
                        result = action_data.get("result", "")
                        floor = action_data.get("floor", 1)
                        side = action_data.get("side", "front")
                        timing = action_data.get("timing", 0)

                        # Determine icon and style based on result
                        if "SUCCESS" in result:
                            icon = "ðŸŽ‰"
                            header = f"{icon} Step {step}: **{tool_name}** - SUCCESS!"
                        elif "error" in tool_name.lower():
                            icon = "âŒ"
                            header = f"{icon} Step {step}: **Error**"
                        elif "step_limit" in tool_name.lower():
                            icon = "âš ï¸"
                            header = f"{icon} Step {step}: **Step Limit Reached**"
                        elif tool_name in ["go_up", "go_down", "go_to_front", "go_to_back"]:
                            icon = "ðŸš¶"
                            header = f"{icon} Step {step}: **{tool_name}**"
                        elif tool_name == "deliver_package":
                            icon = "ðŸ“¦"
                            header = f"{icon} Step {step}: **{tool_name}**"
                        elif "storing_memory" in tool_name:
                            icon = "ðŸ§ "
                            header = f"{icon} **Storing memory...**"
                        elif "memory_stored" in tool_name:
                            icon = "âœ…"
                            header = f"{icon} **Memory stored!**"
                        else:
                            icon = "ðŸ”§"
                            header = f"{icon} Step {step}: **{tool_name}**"

                        with st.expander(header, expanded=False):
                            st.markdown(f"**Result:** {result}")
                            st.caption(f"ðŸ“ Floor {floor}, {side} side | â±ï¸ {timing:.2f}s")

                            # Show LLM prompt/response if available (from combined "step" items)
                            prompt_data = action_data.get("prompt")
                            llm_response = action_data.get("llm_response")
                            if prompt_data or llm_response:
                                st.divider()
                                # Show injection status
                                injection_info = prompt_data.get("_hindsight_injection", {}) if prompt_data else {}
                                if injection_info.get("injected") and injection_info.get("memories_count", 0) > 0:
                                    st.success(f"ðŸ§  {injection_info['memories_count']} memories injected")
                                    # Show the actual injected memories
                                    memory_context = injection_info.get("memory_context", "")
                                    if memory_context:
                                        with st.expander("View injected memories", expanded=False):
                                            st.code(memory_context, language=None)
                                if llm_response:
                                    tool_calls = llm_response.get("tool_calls", [])
                                    if tool_calls:
                                        tc_str = ", ".join([f"{tc.get('name', '?')}({tc.get('arguments', '')})" for tc in tool_calls])
                                        st.markdown(f"**LLM Called:** `{tc_str}`")
                                if prompt_data:
                                    with st.expander("ðŸ“¤ View LLM Prompt", expanded=False):
                                        messages = prompt_data.get("messages", [])
                                        # Show last few messages (most relevant context)
                                        if messages:
                                            st.caption(f"{len(messages)} messages in context")
                                            for msg in messages[-3:]:
                                                role = msg.get("role", "").upper()
                                                content = msg.get("content", "")
                                                if content:
                                                    st.text(f"{role}: {content[:200]}{'...' if len(content) > 200 else ''}")
            else:
                if st.session_state.bg_delivery_running:
                    st.markdown("*Agent is working...*")
                else:
                    st.markdown("*Waiting for delivery...*")

            # Track if we need to refresh (checked at end of function)
            needs_refresh = (
                st.session_state.bg_delivery_running or
                st.session_state.action_queue or
                st.session_state.delivery_complete_pending
            )

        st.markdown("---")

        # Bottom section: Controls, Stats, History (inside ui_tab)
        col_controls, col_stats, col_history = st.columns([1, 1, 1])

        with col_controls:
            # Controls
            st.markdown("### ðŸŽ® Controls")

            # Current package info
            if st.session_state.last_package_info:
                st.markdown("**ðŸ“¦ Current Package:**")
                st.code(st.session_state.last_package_info, language=None)

            # Package options
            include_business = st.checkbox("Include business name", value=st.session_state.include_business,
                                           help="If checked, package will show the business name")
            st.session_state.include_business = include_business

            # Max steps per delivery
            max_steps_ui = st.number_input(
                "Max steps per delivery",
                min_value=1,
                max_value=500,
                value=st.session_state.max_steps_per_delivery,
                placeholder="No limit",
                help="Leave empty for no limit",
                key="ui_max_steps"
            )
            st.session_state.max_steps_per_delivery = max_steps_ui

            # Select Recipient button
            if st.button("ðŸ‘¤ Select Recipient", use_container_width=True):
                st.session_state.show_recipient_dialog = True
                st.session_state.start_delivery_now = False
                st.session_state.selected_recipient = None
                st.rerun()

            # Step by step mode - controls animation speed, not agent speed
            step_by_step = st.checkbox("Step by step mode", value=st.session_state.step_by_step,
                                       help="Click 'Next Step' to advance animations one at a time")
            st.session_state.step_by_step = step_by_step

            # Check if a background delivery is running
            is_delivery_running = st.session_state.bg_delivery_running

            # Generate new package button
            start_new_delivery = st.button("ðŸ“¦ New Delivery", use_container_width=True, disabled=is_delivery_running)

            if start_new_delivery:
                st.session_state.current_actions = []
                st.session_state.action_queue = []
                st.session_state.displayed_actions = []
                st.session_state.last_display_time = 0
                st.session_state.delivery_complete_pending = False
                st.session_state.bg_delivery_complete_info = None  # Clear any previous completion
                # Clear old queue before creating new one - process any pending complete
                complete_item = _clear_queue(st.session_state.session_id)
                _process_complete_item(complete_item)
                st.session_state.bg_queue_active = False
                st.session_state.llm_messages = []
                st.session_state.has_package = True
                st.session_state.agent_floor = 1
                st.session_state.agent_side = "front"
                st.session_state.prev_agent_floor = 1
                st.session_state.prev_agent_side = "front"
                st.session_state.current_action = None
                st.session_state.delivery_start_time = time.time()

                # Use selected recipient or generate random package
                if st.session_state.selected_recipient:
                    recipient_name = st.session_state.selected_recipient
                    business_info = building.find_employee(recipient_name)
                    business_name = business_info[0].name if business_info and include_business else None
                    package = Package(
                        id=f"{random.randint(1000, 9999)}",
                        recipient_name=recipient_name,
                        business_name=business_name
                    )
                else:
                    package = building.generate_package(include_business=include_business)
                st.session_state.last_package_info = str(package)

                # Increment delivery counter and set document_id for memory grouping
                st.session_state.delivery_counter += 1
                memory.set_document_id(f"delivery-{st.session_state.delivery_counter}")

                # Get model
                model = os.environ.get("LLM_MODEL", "openai/gpt-4o-mini")

                # Start background thread for delivery using global queue storage
                action_q = _get_or_create_queue(st.session_state.session_id)
                cancel_evt = _get_or_create_cancel_event(st.session_state.session_id)
                _reset_cancel_event(st.session_state.session_id)  # Clear any previous cancellation
                st.session_state.bg_queue_active = True
                st.session_state.bg_delivery_running = True
                st.session_state.bg_delivery_complete_info = None
                st.session_state.pending_delivery = None  # Clear old pending_delivery

                _debug_log(f"[START] Session {st.session_state.session_id}: {package}, model={model}")

                thread = threading.Thread(
                    target=_run_delivery_in_background,
                    args=(action_q, building, package, model, st.session_state.max_steps_per_delivery, cancel_evt),
                    daemon=True
                )
                thread.start()
                st.rerun()

            # Step-by-step mode: Next Step button advances animations
            if st.session_state.step_by_step and st.session_state.action_queue:
                if st.button("â–¶ï¸ Next Step", use_container_width=True, type="primary"):
                    # Advance one action from the queue
                    next_action = st.session_state.action_queue.pop(0)
                    st.session_state.displayed_actions.append(next_action)
                    st.session_state.last_display_time = time.time()

                    if next_action.get("floor") is not None:
                        st.session_state.prev_agent_floor = st.session_state.agent_floor
                        st.session_state.prev_agent_side = st.session_state.agent_side
                        st.session_state.agent_floor = next_action["floor"]
                        st.session_state.agent_side = next_action["side"]
                        st.session_state.current_action = next_action["tool_name"]
                    st.rerun()

            # Show status when delivery is running
            if is_delivery_running:
                st.info("ðŸ”„ Agent is working... (actions will appear as they complete)")
                if st.button("ðŸ›‘ Stop Delivery", use_container_width=True, type="primary"):
                    _cancel_delivery(st.session_state.session_id)
                    st.toast("Stopping delivery...")
                    st.rerun()
            elif st.session_state.bg_delivery_complete_info:
                info = st.session_state.bg_delivery_complete_info
                if info["success"]:
                    st.success(f"âœ… Delivery complete in {info['steps']} steps!")
                elif info.get("cancelled"):
                    st.warning(f"ðŸ›‘ Delivery cancelled after {info['steps']} steps")
                elif info["error"]:
                    st.error(f"âŒ Delivery failed: {info['error']}")
                else:
                    st.warning(f"âš ï¸ Delivery ended after {info['steps']} steps")

                if st.button("ðŸ”„ Reset", use_container_width=True):
                    st.session_state.bg_delivery_complete_info = None
                    _clear_queue(st.session_state.session_id)
                    st.session_state.bg_queue_active = False
                    st.session_state.action_queue = []
                    st.session_state.displayed_actions = []
                    st.session_state.delivery_complete_pending = False
                    st.rerun()

            # Always-visible Full Reset button - kills everything and starts completely fresh
            if st.button("ðŸ”„ Full Reset", use_container_width=True, type="secondary"):
                # Stop any running background delivery by signaling cancellation
                _cancel_delivery(st.session_state.session_id)
                st.session_state.bg_delivery_running = False
                _clear_queue(st.session_state.session_id)  # Clear and remove the queue
                st.session_state.bg_queue_active = False
                st.session_state.bg_delivery_complete_info = None

                # Clear all delivery state
                st.session_state.action_queue = []
                st.session_state.displayed_actions = []
                st.session_state.delivery_complete_pending = False
                st.session_state.llm_messages = []
                st.session_state.has_package = False
                st.session_state.last_package_info = None
                st.session_state.current_action = None
                st.session_state.agent_floor = 1
                st.session_state.agent_side = "front"
                st.session_state.prev_agent_floor = 1
                st.session_state.prev_agent_side = "front"

                # CRITICAL: Reset delivery trigger flags to prevent auto-start
                st.session_state.start_delivery_now = False
                st.session_state.show_recipient_dialog = False
                st.session_state.pending_delivery = None
                st.session_state.fast_forward = False

                # Generate new session and bank ID (fresh memory)
                st.session_state.session_id = uuid.uuid4().hex[:8]
                bank_id = memory.configure_memory(session_id=st.session_state.session_id)
                st.session_state.bank_id = bank_id

                # Reset stats
                st.session_state.deliveries_completed = 0
                st.session_state.delivery_counter = 0
                st.session_state.total_steps = 0
                st.session_state.delivery_history = []
                st.session_state.current_actions = []
                st.session_state.selected_recipient = None
                st.session_state.selected_business = None
                st.session_state.stored_memories = []
                st.session_state.loop_remaining = 0
                st.session_state.is_running = False

                st.rerun()

            # Clear Memory button (keeps stats, just clears hindsight memory)
            if st.button("ðŸ§¹ Clear Memory", use_container_width=True, disabled=st.session_state.is_running):
                st.session_state.session_id = uuid.uuid4().hex[:8]
                bank_id = memory.configure_memory(session_id=st.session_state.session_id)
                st.session_state.bank_id = bank_id
                st.session_state.deliveries_completed = 0
                st.session_state.delivery_counter = 0  # Reset delivery counter
                st.session_state.loop_remaining = 0  # Stop any active loop
                st.session_state.total_steps = 0
                st.session_state.delivery_history = []
                st.session_state.current_actions = []
                st.session_state.has_package = False
                st.session_state.last_package_info = None
                st.session_state.current_action = None
                st.session_state.selected_recipient = None
                st.session_state.llm_messages = []
                st.session_state.stored_memories = []
                st.rerun()

        with col_stats:
            # Stats panel
            st.markdown("### ðŸ“Š Stats")

            # Memory Bank ID with copy button (compact)
            bank_id = st.session_state.get('bank_id', 'N/A')
            bank_col1, bank_col2 = st.columns([1, 2])
            with bank_col1:
                st.markdown("ðŸ¦ **Bank:**")
            with bank_col2:
                st.code(bank_id, language=None)

            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("Deliveries", st.session_state.deliveries_completed)
            with col_b:
                st.metric("Total Steps", st.session_state.total_steps)

            if st.session_state.deliveries_completed > 0:
                avg_steps = st.session_state.total_steps / st.session_state.deliveries_completed
                st.metric("Avg Steps", f"{avg_steps:.1f}")

            # Timing Benchmarks
            if st.session_state.get("timing_llm_calls") or st.session_state.get("timing_deliveries"):
                st.markdown("### â±ï¸ Benchmarks")

                llm_times = st.session_state.get("timing_llm_calls", [])
                delivery_times = st.session_state.get("timing_deliveries", [])

                if llm_times:
                    avg_llm = sum(llm_times) / len(llm_times)
                    st.metric("Avg LLM Call", f"{avg_llm:.2f}s")

                if delivery_times:
                    avg_delivery = sum(delivery_times) / len(delivery_times)
                    st.metric("Avg Delivery", f"{avg_delivery:.1f}s")

                # Total loop time
                if st.session_state.get("timing_loop_start") and delivery_times:
                    total_loop = time.time() - st.session_state.timing_loop_start
                    st.metric("Total Loop Time", f"{total_loop:.1f}s")
                    st.caption(f"{len(llm_times)} LLM calls | {len(delivery_times)} deliveries")

        with col_history:
            # Delivery history
            st.markdown("### ðŸ“œ History")
            if st.session_state.delivery_history:
                for i, delivery in enumerate(reversed(st.session_state.delivery_history[-5:]), 1):
                    status = "âœ…" if delivery["success"] else "âŒ"
                    st.markdown(f"{status} **{delivery['steps']} steps** ðŸ§ ")
            else:
                st.markdown("*No deliveries yet*")

            # Learning curve visualization
            if len(st.session_state.delivery_history) >= 1:
                st.markdown("### ðŸ“ˆ Learning Curve")
                steps_history = [d["steps"] for d in st.session_state.delivery_history]
                # Create DataFrame with 1-indexed delivery numbers as column
                df = pd.DataFrame({
                    "Delivery": range(1, len(steps_history) + 1),
                    "Steps": steps_history
                })
                st.line_chart(df, x="Delivery", y="Steps", use_container_width=True)

        # LLM Debug Section - scrollable, organized display
        st.markdown("### ðŸ¤– LLM Prompt & Response")
        if st.session_state.llm_messages:
            # Scrollable container
            llm_container = st.container(height=500)
            with llm_container:
                for entry in reversed(st.session_state.llm_messages):  # Newest first
                    step_num = entry.get("step", "?")
                    with st.expander(f"**Step {step_num}**", expanded=False):
                        # Use dict-based format (no JSON parsing needed)
                        prompt_data = entry.get("prompt", {})
                        response_data = entry.get("response", {})

                        try:
                            messages = prompt_data.get("messages", [])
                            injection_info = prompt_data.get("_hindsight_injection", {})

                            # Separate messages by type
                            system_msg = None
                            history_messages = []
                            current_message = None

                            for msg in messages:
                                role = msg.get("role", "")
                                if role == "system":
                                    system_msg = msg
                                elif msg == messages[-1]:
                                    current_message = msg
                                else:
                                    history_messages.append(msg)

                            # 1. History (collapsed) - previous conversation turns
                            if history_messages:
                                with st.expander(f"ðŸ“œ History ({len(history_messages)} messages)", expanded=False):
                                    for msg in history_messages:
                                        role = msg.get("role", "").upper()
                                        content = msg.get("content", "")
                                        tool_calls = msg.get("tool_calls", [])

                                        if role == "USER":
                                            st.caption(f"**USER:** {content}")
                                        elif role == "ASSISTANT" and tool_calls:
                                            # Handle both formats: {"name": ...} or {"function": {"name": ...}}
                                            tc_names = [tc.get("function", {}).get("name", "") or tc.get("name", "") for tc in tool_calls]
                                            st.caption(f"**ASSISTANT:** called {', '.join(tc_names)}")
                                        elif role == "TOOL":
                                            st.caption(f"**TOOL:** {content[:100]}..." if len(content) > 100 else f"**TOOL:** {content}")
                                        else:
                                            st.caption(f"**{role}:** {content[:100]}..." if len(content) > 100 else f"**{role}:** {content}")

                            # 2. System Prompt (with injected memories)
                            st.markdown("**ðŸ”§ System Prompt:**")
                            if system_msg:
                                system_content = system_msg.get("content", "")
                                # Check if memories were injected
                                injected = injection_info.get("injected", False) if injection_info else False
                                memories_count = injection_info.get("memories_count", 0) if injection_info else 0
                                memory_context = injection_info.get("memory_context", "") if injection_info else ""

                                if injected and memories_count > 0:
                                    st.success(f"ðŸ§  {memories_count} memories injected")
                                    # Show actual injected memories (from memory_context)
                                    if memory_context:
                                        with st.expander("View injected memories", expanded=True):
                                            st.code(memory_context, language=None)
                                    # Show original system prompt
                                    with st.expander("View original system prompt", expanded=False):
                                        st.code(system_content, language=None)
                                else:
                                    st.caption("ðŸ§  No memories injected")
                                    st.code(system_content, language=None)
                            else:
                                st.caption("No system prompt")

                            # 3. Tools available
                            tools = prompt_data.get("tools", [])
                            if tools:
                                with st.expander(f"ðŸ”§ Tools ({len(tools)} available)", expanded=False):
                                    tool_names = [t.get("function", {}).get("name", "?") for t in tools]
                                    st.write(", ".join(tool_names))

                            # 4. Current (the latest message being sent)
                            st.markdown("**ðŸ“¤ Current:**")
                            if current_message:
                                st.json(current_message)
                            else:
                                st.caption("No current message")

                            st.divider()

                            # 5. Response
                            st.markdown("**ðŸ“¥ Response:**")
                            st.json(response_data)

                            st.divider()

                            # 5. Raw Prompt & Response (for debugging)
                            with st.expander("ðŸ” Raw Prompt & Response (Debug)", expanded=False):
                                st.markdown("**Raw Prompt (full JSON sent to LLM):**")
                                st.code(json.dumps(prompt_data, indent=2), language="json")
                                st.markdown("**Raw Response (full JSON from LLM):**")
                                st.code(json.dumps(response_data, indent=2), language="json")

                        except Exception as e:
                            st.error(f"Parse error: {e}")
                            st.json(prompt_data)
        else:
            st.caption("*No LLM calls yet*")

        # Auto-refresh at the end, after all UI has been rendered
        # This allows all sections (including LLM) to display before refreshing
        if needs_refresh and not st.session_state.step_by_step:
            time.sleep(0.3)  # Poll interval
            st.rerun()


if __name__ == "__main__":
    main()
