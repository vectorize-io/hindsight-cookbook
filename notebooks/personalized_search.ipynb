{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Personalized Search Agent with Hindsight Memory\n\nA search assistant that learns your preferences, location, dietary needs, and lifestyle to provide contextually relevant search results.\n\n## Features\n- Learns location, dietary restrictions, and lifestyle\n- Personalizes search queries based on context\n- Remembers past searches and preferences\n- Integrates with Tavily for real web search (optional)\n\n## Prerequisites\n- OpenAI API key\n- Hindsight running locally via Docker (see setup below)\n- Tavily API key (optional, for real web search)\n\n## Start Hindsight Locally\n\nBefore running this notebook, start Hindsight in a terminal:\n\n```bash\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\ndocker run --rm -it --pull always -p 8888:8888 -p 9999:9999 \\\n  -e HINDSIGHT_API_LLM_API_KEY=$OPENAI_API_KEY \\\n  -e HINDSIGHT_API_LLM_MODEL=gpt-4o-mini \\\n  -v $HOME/.hindsight-docker:/home/hindsight/.pg0 \\\n  ghcr.io/vectorize-io/hindsight:latest\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tavily is optional - demo works with simulated results if not installed\n!pip install -q hindsight-client openai tavily-python nest-asyncio"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Configure API Keys\n\nEnter your API keys when prompted. Tavily is optional - press Enter to skip for simulated search results."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import getpass\nimport os\nimport sys\n\n# Set OpenAI API key (used by both Hindsight and the demo)\nif not os.getenv(\"OPENAI_API_KEY\"):\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n\n# Tavily is optional - for real web search\n# Skip prompt in non-interactive environments (CI, nbmake)\nif not os.getenv(\"TAVILY_API_KEY\") and sys.stdin and sys.stdin.isatty():\n    tavily_key = getpass.getpass(\"Enter your Tavily API key (or press Enter to skip): \")\n    if tavily_key:\n        os.environ[\"TAVILY_API_KEY\"] = tavily_key\n\nprint(\"API keys configured!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import nest_asyncio\nnest_asyncio.apply()\n\nfrom openai import OpenAI\nfrom hindsight_client import Hindsight\n\n# Initialize Hindsight client (connects to local Docker instance)\nhindsight = Hindsight(\n    base_url=os.getenv(\"HINDSIGHT_BASE_URL\", \"http://localhost:8888\"),\n)\n\nopenai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Optional: Tavily for real web search\ntry:\n    from tavily import TavilyClient\n    tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n    HAS_TAVILY = True\n    print(\"Tavily configured - using real web search!\")\nexcept (ImportError, Exception) as e:\n    HAS_TAVILY = False\n    print(\"Note: Using simulated search results (Tavily not configured)\")\n\nUSER_ID = \"search-user-demo\"\n\nprint(\"Clients initialized!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_preference(preference: str) -> str:\n",
    "    \"\"\"Store a user preference.\"\"\"\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"User preference: {preference}\",\n",
    "        metadata={\"category\": \"preference\"},\n",
    "    )\n",
    "    return f\"Learned: {preference}\"\n",
    "\n",
    "\n",
    "def store_interaction(query: str, response: str) -> None:\n",
    "    \"\"\"Store a search interaction.\"\"\"\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"Search query: {query}\\nResult highlights: {response[:200]}\",\n",
    "        metadata={\"category\": \"search_history\"},\n",
    "    )\n",
    "\n",
    "\n",
    "def get_user_context(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant user context.\"\"\"\n",
    "    memories = hindsight.recall(\n",
    "        bank_id=USER_ID,\n",
    "        query=f\"preferences location dietary lifestyle {query}\",\n",
    "        budget=\"mid\",\n",
    "    )\n",
    "\n",
    "    if memories and memories.results:\n",
    "        return \"\\n\".join(f\"- {m.text}\" for m in memories.results[:6])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def personalized_search(query: str) -> str:\n",
    "    \"\"\"Perform a personalized search.\"\"\"\n",
    "    user_context = get_user_context(query)\n",
    "\n",
    "    enhancement_prompt = f\"\"\"Given this user's preferences and the search query, suggest how to enhance the search.\n",
    "\n",
    "User preferences:\n",
    "{user_context if user_context else \"No preferences recorded yet.\"}\n",
    "\n",
    "Search query: {query}\n",
    "\n",
    "Return a JSON object with:\n",
    "- \"enhanced_query\": The improved search query incorporating relevant preferences\n",
    "- \"filters\": Any specific filters to apply (e.g., \"vegetarian\", \"within 5 miles\")\n",
    "- \"reasoning\": Brief explanation of personalizations applied\"\"\"\n",
    "\n",
    "    enhancement = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": enhancement_prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    enhanced_info = enhancement.choices[0].message.content\n",
    "\n",
    "    # Perform the search\n",
    "    if HAS_TAVILY:\n",
    "        search_results = tavily.search(\n",
    "            query=query,\n",
    "            search_depth=\"advanced\",\n",
    "            max_results=5,\n",
    "        )\n",
    "        results_text = \"\\n\".join(\n",
    "            f\"- {r['title']}: {r['content'][:150]}...\"\n",
    "            for r in search_results.get('results', [])\n",
    "        )\n",
    "    else:\n",
    "        results_text = f\"[Simulated search results for: {query}]\"\n",
    "\n",
    "    response_prompt = f\"\"\"Based on the search results and user preferences, provide a personalized summary.\n",
    "\n",
    "User preferences:\n",
    "{user_context if user_context else \"No preferences recorded yet.\"}\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Search enhancement applied:\n",
    "{enhanced_info}\n",
    "\n",
    "Search results:\n",
    "{results_text}\n",
    "\n",
    "Provide a helpful, personalized response that takes into account their preferences.\"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": response_prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    store_interaction(query, answer)\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "def get_preference_profile() -> str:\n",
    "    \"\"\"Get a summary of the user's preference profile.\"\"\"\n",
    "    profile = hindsight.reflect(\n",
    "        bank_id=USER_ID,\n",
    "        query=\"\"\"Summarize what we know about this user:\n",
    "        - Location and neighborhood\n",
    "        - Dietary preferences and restrictions\n",
    "        - Work style and schedule\n",
    "        - Hobbies and interests\n",
    "        - Family situation\n",
    "        - Shopping preferences\"\"\",\n",
    "        budget=\"high\",\n",
    "    )\n",
    "    return profile.text if hasattr(profile, 'text') else str(profile)\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Learning user preferences...\")\n",
    "\n",
    "preferences = [\n",
    "    \"Lives in San Francisco, Mission District\",\n",
    "    \"Works remotely as a software engineer\",\n",
    "    \"Vegetarian, prefers organic food when possible\",\n",
    "    \"Has a 5-year-old daughter named Emma\",\n",
    "    \"Enjoys hiking and outdoor activities on weekends\",\n",
    "    \"Prefers quiet coffee shops for remote work\",\n",
    "    \"Lactose intolerant, uses oat milk\",\n",
    "    \"Interested in sustainable and eco-friendly products\",\n",
    "    \"Usually free on Tuesday and Thursday afternoons\",\n",
    "    \"Husband is allergic to nuts\",\n",
    "]\n",
    "\n",
    "for pref in preferences:\n",
    "    result = store_preference(pref)\n",
    "    print(f\"  {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Personalized Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Personalized Search Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "searches = [\n",
    "    \"Find a good coffee shop for working remotely\",\n",
    "    \"Restaurant recommendations for a family dinner\",\n",
    "    \"Birthday gift ideas for a 5-year-old\",\n",
    "]\n",
    "\n",
    "for query in searches:\n",
    "    print(f\"\\nSearch: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    result = personalized_search(query)\n",
    "    print(result)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Preference Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  User Preference Profile\")\n",
    "print(\"=\" * 60)\n",
    "print(get_preference_profile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Try Your Own Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_search = \"Best hiking trails near me\"  # Change this!\n",
    "\n",
    "print(f\"Search: {your_search}\")\n",
    "print(\"-\" * 40)\n",
    "print(personalized_search(your_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindsight.close()\n",
    "print(\"Client connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "tags": {
   "sdk": "hindsight-client",
   "topic": "Recommendation"
  },
  "description": "Search assistant that learns your location, diet, and lifestyle"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}