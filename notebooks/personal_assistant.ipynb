{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal AI Assistant with Hindsight Memory\n",
    "\n",
    "A general-purpose personal assistant that remembers your preferences, schedule, family, work context, and past conversations.\n",
    "\n",
    "## Features\n",
    "- Remembers family, work, and personal details\n",
    "- Tracks preferences and habits\n",
    "- Helps with scheduling and reminders\n",
    "- Maintains context across conversations\n",
    "\n",
    "## Prerequisites\n",
    "- OpenAI API key\n",
    "- Hindsight running locally via Docker (see setup below)\n",
    "\n",
    "## Start Hindsight Locally\n",
    "\n",
    "Before running this notebook, start Hindsight in a terminal:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "\n",
    "docker run --rm -it --pull always -p 8888:8888 -p 9999:9999 \\\n",
    "  -e HINDSIGHT_API_LLM_API_KEY=$OPENAI_API_KEY \\\n",
    "  -e HINDSIGHT_API_LLM_MODEL=gpt-4o-mini \\\n",
    "  -v $HOME/.hindsight-docker:/home/hindsight/.pg0 \\\n",
    "  ghcr.io/vectorize-io/hindsight:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q hindsight-client openai nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure OpenAI API Key\n",
    "\n",
    "Enter your OpenAI API key when prompted (used by both Hindsight and the demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key (used by both Hindsight and the demo)\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from hindsight_client import Hindsight\n",
    "\n",
    "# Initialize Hindsight client (connects to local Docker instance)\n",
    "hindsight = Hindsight(\n",
    "    base_url=os.getenv(\"HINDSIGHT_BASE_URL\", \"http://localhost:8888\"),\n",
    ")\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "USER_ID = \"assistant-user-demo\"\n",
    "\n",
    "print(\"Clients initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remember(info: str, category: str = \"general\") -> str:\n",
    "    \"\"\"Store information to remember.\"\"\"\n",
    "    today = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"{today}: {info}\",\n",
    "        metadata={\"category\": category, \"date\": today},\n",
    "    )\n",
    "\n",
    "    return f\"I'll remember: {info}\"\n",
    "\n",
    "\n",
    "def recall_context(query: str) -> str:\n",
    "    \"\"\"Recall relevant memories for context.\"\"\"\n",
    "    memories = hindsight.recall(\n",
    "        bank_id=USER_ID,\n",
    "        query=query,\n",
    "        budget=\"high\",\n",
    "    )\n",
    "\n",
    "    if memories and memories.results:\n",
    "        return \"\\n\".join(f\"- {m.text}\" for m in memories.results[:8])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def chat(user_message: str) -> str:\n",
    "    \"\"\"Chat with the personal assistant.\"\"\"\n",
    "    context = recall_context(user_message)\n",
    "\n",
    "    system_prompt = f\"\"\"You are a helpful personal AI assistant with long-term memory.\n",
    "You remember the user's preferences, schedule, family, work context, and past conversations.\n",
    "\n",
    "What you remember about this user:\n",
    "{context if context else \"No memories recorded yet.\"}\n",
    "\n",
    "Your capabilities:\n",
    "- Remember things when asked (\"Remember that...\", \"Don't forget...\")\n",
    "- Recall past information (\"What did I tell you about...\", \"When is...\")\n",
    "- Provide personalized suggestions based on known preferences\n",
    "- Help with scheduling and reminders\n",
    "- Have natural conversations while maintaining context\n",
    "\n",
    "Be helpful, proactive, and reference relevant memories naturally.\"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # Check if user is asking to remember something\n",
    "    lower_msg = user_message.lower()\n",
    "    if any(phrase in lower_msg for phrase in [\"remember that\", \"don't forget\", \"remind me\", \"note that\"]):\n",
    "        hindsight.retain(\n",
    "            bank_id=USER_ID,\n",
    "            content=f\"User asked to remember: {user_message}\",\n",
    "            metadata={\"category\": \"reminder\"},\n",
    "        )\n",
    "\n",
    "    # Store the interaction\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"Conversation - User: {user_message[:100]} | Assistant: {answer[:100]}\",\n",
    "        metadata={\"category\": \"conversation\"},\n",
    "    )\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "def get_summary(topic: str = None) -> str:\n",
    "    \"\"\"Get a summary of memories.\"\"\"\n",
    "    query = f\"Summarize what you know about {topic}\" if topic else \\\n",
    "            \"Summarize everything you know about this user\"\n",
    "\n",
    "    summary = hindsight.reflect(\n",
    "        bank_id=USER_ID,\n",
    "        query=query,\n",
    "        budget=\"high\",\n",
    "    )\n",
    "    return summary.text if hasattr(summary, 'text') else str(summary)\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building context...\")\n",
    "\n",
    "initial_context = [\n",
    "    (\"My name is Alex and I work as a product manager at TechCorp\", \"personal\"),\n",
    "    (\"My wife's name is Sarah and we have two kids: Emma (7) and Jack (4)\", \"family\"),\n",
    "    (\"I prefer morning meetings and try to keep afternoons for deep work\", \"preference\"),\n",
    "    (\"My mom's birthday is March 15th\", \"event\"),\n",
    "    (\"I'm trying to read more - currently reading 'Atomic Habits'\", \"hobby\"),\n",
    "    (\"I have a weekly team standup every Monday at 10am\", \"schedule\"),\n",
    "    (\"I'm allergic to cats\", \"health\"),\n",
    "    (\"My favorite coffee is a flat white with oat milk\", \"preference\"),\n",
    "    (\"I'm training for a half marathon in April\", \"goal\"),\n",
    "]\n",
    "\n",
    "for info, category in initial_context:\n",
    "    result = remember(info, category)\n",
    "    print(f\"  {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Have a Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Conversation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "conversations = [\n",
    "    \"Hey, what's my wife's name again?\",\n",
    "    \"Remember that my Q1 review is next Thursday at 2pm\",\n",
    "    \"I need a gift idea for my mom's birthday\",\n",
    "    \"What time is my Monday standup?\",\n",
    "    \"Can you recommend a coffee order for me?\",\n",
    "    \"What books am I reading?\",\n",
    "]\n",
    "\n",
    "for message in conversations:\n",
    "    print(f\"\\nAlex: {message}\")\n",
    "    print(\"-\" * 40)\n",
    "    response = chat(message)\n",
    "    print(f\"Assistant: {response}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  What I Know About You\")\n",
    "print(\"=\" * 60)\n",
    "print(get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  Your Family\")\n",
    "print(\"=\" * 60)\n",
    "print(get_summary(\"family\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Try Your Own Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_message = \"What should I focus on this month with my training?\"  # Change this!\n",
    "\n",
    "print(f\"You: {your_message}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Assistant: {chat(your_message)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindsight.close()\n",
    "print(\"Client connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "tags": {
   "language": "Python",
   "sdk": "Hindsight Client",
   "topic": "Recommendation"
  },
  "description": "A general-purpose assistant that remembers your life and preferences"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}