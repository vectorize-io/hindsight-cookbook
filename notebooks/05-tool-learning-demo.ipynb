{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindsight Tool Learning Demo\n",
    "\n",
    "This notebook demonstrates how Hindsight helps an LLM learn which tool to use when tool names are ambiguous. Without memory, the LLM might randomly select between similarly-named tools. With Hindsight, it learns from past interactions and consistently makes the correct choice.\n",
    "\n",
    "## The Scenario\n",
    "\n",
    "We have a task routing system with two tools:\n",
    "- `route_to_channel_alpha` - Routes to processing channel Alpha\n",
    "- `route_to_channel_omega` - Routes to processing channel Omega\n",
    "\n",
    "The tool names and descriptions are **intentionally vague**. In reality:\n",
    "- Channel Alpha handles **FINANCIAL/PAYMENT** tasks (refunds, billing, etc.)\n",
    "- Channel Omega handles **TECHNICAL/SUPPORT** tasks (bugs, features, etc.)\n",
    "\n",
    "**Without Hindsight:** The LLM guesses randomly based on vague descriptions  \n",
    "**With Hindsight:** The LLM learns from feedback which channel handles what\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have Hindsight running:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your-key\n",
    "\n",
    "docker run --rm -it --pull always -p 8888:8888 -p 9999:9999 \\\n",
    "  -e HINDSIGHT_API_LLM_API_KEY=$OPENAI_API_KEY \\\n",
    "  -e HINDSIGHT_API_LLM_MODEL=o3-mini \\\n",
    "  -v $HOME/.hindsight-docker:/home/hindsight/.pg0 \\\n",
    "  ghcr.io/vectorize-io/hindsight:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hindsight-litellm hindsight-client litellm nest_asyncio python-dotenv -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import logging\n",
    "import nest_asyncio\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"LiteLLM Router\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "import litellm\n",
    "import hindsight_litellm\n",
    "from hindsight_client import Hindsight\n",
    "\n",
    "HINDSIGHT_API_URL = os.getenv(\"HINDSIGHT_API_URL\", \"http://localhost:8888\")\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Warning: OPENAI_API_KEY not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "These tool definitions are **intentionally ambiguous** - the descriptions don't reveal which channel handles what type of request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"route_to_channel_alpha\",\n",
    "            \"description\": \"Routes the customer request to processing channel Alpha. Use this channel for appropriate request types.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"request_summary\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A brief summary of the customer's request\"\n",
    "                    },\n",
    "                    \"priority\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"low\", \"medium\", \"high\"],\n",
    "                        \"description\": \"Priority level of the request\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"request_summary\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"route_to_channel_omega\",\n",
    "            \"description\": \"Routes the customer request to processing channel Omega. Use this channel for appropriate request types.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"request_summary\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A brief summary of the customer's request\"\n",
    "                    },\n",
    "                    \"priority\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"low\", \"medium\", \"high\"],\n",
    "                        \"description\": \"Priority level of the request\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"request_summary\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Scenarios\n",
    "\n",
    "A mix of financial and technical requests to test routing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SCENARIOS = [\n",
    "    {\n",
    "        \"type\": \"financial\",\n",
    "        \"request\": \"I was charged twice for my subscription last month. I need a refund for the duplicate charge.\",\n",
    "        \"correct_tool\": \"route_to_channel_alpha\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"technical\",\n",
    "        \"request\": \"The app keeps crashing when I try to upload a file larger than 10MB. This bug is blocking my work.\",\n",
    "        \"correct_tool\": \"route_to_channel_omega\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"financial\",\n",
    "        \"request\": \"My invoice shows an incorrect amount. The billing department needs to fix this.\",\n",
    "        \"correct_tool\": \"route_to_channel_alpha\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"technical\",\n",
    "        \"request\": \"I'd like to request a new feature: the ability to export reports as PDF.\",\n",
    "        \"correct_tool\": \"route_to_channel_omega\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"financial\",\n",
    "        \"request\": \"I need to update my payment method and understand why my last payment failed.\",\n",
    "        \"correct_tool\": \"route_to_channel_alpha\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a customer service routing agent. Your job is to route customer requests to the appropriate processing channel.\n",
    "\n",
    "You have access to two routing channels:\n",
    "- route_to_channel_alpha: Routes to channel Alpha\n",
    "- route_to_channel_omega: Routes to channel Omega\n",
    "\n",
    "Analyze the customer's request and route it to the most appropriate channel. You must call one of the routing functions to process the request.\n",
    "\n",
    "Important: Base your routing decision on what you know about each channel's purpose. If you have learned from previous interactions which channel handles specific types of requests, use that knowledge.\"\"\"\n",
    "\n",
    "\n",
    "def make_routing_request(user_request: str, use_hindsight: bool, bank_id: Optional[str] = None):\n",
    "    \"\"\"Make a routing request and return the tool called.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Customer Request: {user_request}\"}\n",
    "    ]\n",
    "\n",
    "    if use_hindsight and bank_id:\n",
    "        response = hindsight_litellm.completion(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=TOOLS,\n",
    "            tool_choice=\"required\",\n",
    "            temperature=0.0,\n",
    "        )\n",
    "    else:\n",
    "        response = litellm.completion(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=TOOLS,\n",
    "            tool_choice=\"required\",\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "        return tool_call.function.name\n",
    "    return None\n",
    "\n",
    "\n",
    "def store_feedback(bank_id: str, request: str, correct_tool: str, request_type: str):\n",
    "    \"\"\"Store feedback about which tool was correct for a request type.\"\"\"\n",
    "    client = Hindsight(base_url=HINDSIGHT_API_URL, timeout=60.0)\n",
    "\n",
    "    feedback_content = f\"\"\"ROUTING FEEDBACK:\n",
    "Request type: {request_type}\n",
    "Customer request: \"{request}\"\n",
    "Correct routing: {correct_tool}\n",
    "\n",
    "LEARNED RULE: {request_type.upper()} requests (like refunds, billing, payments, charges, invoices) should ALWAYS be routed to {correct_tool}.\n",
    "This is important institutional knowledge for routing decisions.\"\"\"\n",
    "\n",
    "    client.retain(\n",
    "        bank_id=bank_id,\n",
    "        content=feedback_content,\n",
    "        context=f\"routing:feedback:{request_type}\",\n",
    "        metadata={\"request_type\": request_type, \"correct_tool\": correct_tool}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Without Hindsight (No Memory)\n",
    "\n",
    "The LLM has no prior knowledge about which channel handles what. With ambiguous tool descriptions, it may route incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: WITHOUT HINDSIGHT (No Memory)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "phase1_results = []\n",
    "for i, scenario in enumerate(TEST_SCENARIOS[:3], 1):\n",
    "    print(f\"\\n--- Test {i}: {scenario['type'].upper()} Request ---\")\n",
    "    print(f\"Request: \\\"{scenario['request'][:60]}...\\\"\")\n",
    "\n",
    "    tool_name = make_routing_request(scenario['request'], use_hindsight=False)\n",
    "\n",
    "    is_correct = tool_name == scenario['correct_tool']\n",
    "    phase1_results.append(is_correct)\n",
    "\n",
    "    print(f\"LLM chose: {tool_name}\")\n",
    "    print(f\"Correct tool: {scenario['correct_tool']}\")\n",
    "    print(f\"Result: {'âœ“ CORRECT' if is_correct else 'âœ— INCORRECT'}\")\n",
    "\n",
    "phase1_accuracy = sum(phase1_results) / len(phase1_results) * 100\n",
    "print(f\"\\n>>> Phase 1 Accuracy: {phase1_accuracy:.0f}% ({sum(phase1_results)}/{len(phase1_results)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Teaching Phase\n",
    "\n",
    "Now we provide feedback about correct routing to build memory. This simulates a human supervisor correcting the AI's routing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_id = f\"tool-learning-{uuid.uuid4().hex[:8]}\"\n",
    "print(f\"Using bank_id: {bank_id}\")\n",
    "\n",
    "# Configure and enable Hindsight\n",
    "hindsight_litellm.configure(\n",
    "    hindsight_api_url=HINDSIGHT_API_URL,\n",
    "    bank_id=bank_id,\n",
    "    store_conversations=True,\n",
    "    inject_memories=True,\n",
    "    max_memories=10,\n",
    "    recall_budget=\"high\",\n",
    "    verbose=False,\n",
    ")\n",
    "hindsight_litellm.enable()\n",
    "\n",
    "print(\"\\nStoring routing feedback...\")\n",
    "\n",
    "feedback_examples = [\n",
    "    (\"I need a refund for an incorrect charge on my account.\", \"route_to_channel_alpha\", \"financial\"),\n",
    "    (\"There's a bug in the system causing data loss.\", \"route_to_channel_omega\", \"technical\"),\n",
    "    (\"My billing statement has errors that need correction.\", \"route_to_channel_alpha\", \"financial\"),\n",
    "    (\"I want to request a new feature for the dashboard.\", \"route_to_channel_omega\", \"technical\"),\n",
    "]\n",
    "\n",
    "for request, correct_tool, req_type in feedback_examples:\n",
    "    print(f\"  Storing: {req_type.upper()} â†’ {correct_tool}\")\n",
    "    store_feedback(bank_id, request, correct_tool, req_type)\n",
    "\n",
    "print(\"\\nWaiting 15 seconds for Hindsight to process memories...\")\n",
    "time.sleep(15)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: With Hindsight (Memory-Augmented)\n",
    "\n",
    "The LLM now has access to learned routing knowledge via Hindsight. It should route requests correctly based on past feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 3: WITH HINDSIGHT (Memory-Augmented)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "phase3_results = []\n",
    "for i, scenario in enumerate(TEST_SCENARIOS, 1):\n",
    "    print(f\"\\n--- Test {i}: {scenario['type'].upper()} Request ---\")\n",
    "    print(f\"Request: \\\"{scenario['request'][:60]}...\\\"\")\n",
    "\n",
    "    tool_name = make_routing_request(\n",
    "        scenario['request'],\n",
    "        use_hindsight=True,\n",
    "        bank_id=bank_id\n",
    "    )\n",
    "\n",
    "    is_correct = tool_name == scenario['correct_tool']\n",
    "    phase3_results.append(is_correct)\n",
    "\n",
    "    print(f\"LLM chose: {tool_name}\")\n",
    "    print(f\"Correct tool: {scenario['correct_tool']}\")\n",
    "    print(f\"Result: {'âœ“ CORRECT' if is_correct else 'âœ— INCORRECT'}\")\n",
    "\n",
    "phase3_accuracy = sum(phase3_results) / len(phase3_results) * 100\n",
    "print(f\"\\n>>> Phase 3 Accuracy: {phase3_accuracy:.0f}% ({sum(phase3_results)}/{len(phase3_results)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nPhase 1 (No Memory):      {phase1_accuracy:.0f}% accuracy\")\n",
    "print(f\"Phase 3 (With Hindsight): {phase3_accuracy:.0f}% accuracy\")\n",
    "\n",
    "improvement = phase3_accuracy - phase1_accuracy\n",
    "if improvement > 0:\n",
    "    print(f\"\\nðŸŽ‰ Improvement: +{improvement:.0f}% accuracy with Hindsight!\")\n",
    "elif improvement == 0:\n",
    "    print(f\"\\nNote: Results may vary. Run again to see learning effect.\")\n",
    "else:\n",
    "    print(f\"\\nNote: Phase 1 got lucky! Run again to see typical behavior.\")\n",
    "\n",
    "print(f\"\\nMemories stored in bank: {bank_id}\")\n",
    "print(f\"View in UI: http://localhost:9999/banks/{bank_id}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Hindsight allows the LLM to learn from experience which tool\")\n",
    "print(\"to use, even when tool names/descriptions are ambiguous.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindsight_litellm.cleanup()\n",
    "\n",
    "# Optional: delete the bank\n",
    "import requests\n",
    "response = requests.delete(f\"{HINDSIGHT_API_URL}/v1/default/banks/{bank_id}\")\n",
    "print(f\"Deleted bank: {response.json()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
