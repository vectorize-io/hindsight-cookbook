{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Movie Recommendation Assistant with Hindsight Memory\n\nA personalized movie recommender that remembers your preferences, watch history, and tastes to give better suggestions over time.\n\n## Features\n- Remembers favorite genres, directors, and actors\n- Tracks movies you've watched and enjoyed\n- Provides contextual recommendations based on mood\n\n## Prerequisites\n- OpenAI API key\n- Hindsight running locally via Docker (see setup below)\n\n## Start Hindsight Locally\n\nBefore running this notebook, start Hindsight in a terminal:\n\n```bash\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\ndocker run --rm -it --pull always -p 8888:8888 -p 9999:9999 \\\n  -e HINDSIGHT_API_LLM_API_KEY=$OPENAI_API_KEY \\\n  -e HINDSIGHT_API_LLM_MODEL=gpt-4o-mini \\\n  -v $HOME/.hindsight-docker:/home/hindsight/.pg0 \\\n  ghcr.io/vectorize-io/hindsight:latest\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q hindsight-client openai nest-asyncio"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Configure OpenAI API Key\n\nEnter your OpenAI API key when prompted (used by both Hindsight and the demo)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import getpass\nimport os\n\n# Set OpenAI API key (used by both Hindsight and the demo)\nif not os.getenv(\"OPENAI_API_KEY\"):\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n\nprint(\"API key configured!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import nest_asyncio\nnest_asyncio.apply()\n\nfrom openai import OpenAI\nfrom hindsight_client import Hindsight\n\n# Initialize Hindsight client (connects to local Docker instance)\nhindsight = Hindsight(\n    base_url=os.getenv(\"HINDSIGHT_BASE_URL\", \"http://localhost:8888\"),\n)\n\n# Initialize OpenAI client\nopenai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# Unique identifier for this user's memory bank\nUSER_ID = \"movie-fan-demo\"\n\nprint(\"Clients initialized!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Helper Functions\n",
    "\n",
    "These functions demonstrate the three core Hindsight operations:\n",
    "- **retain()**: Store memories\n",
    "- **recall()**: Retrieve relevant memories\n",
    "- **reflect()**: Synthesize insights from memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Get a movie recommendation based on user query and remembered preferences.\n",
    "    \"\"\"\n",
    "    # Recall relevant memories about this user's movie preferences\n",
    "    memories = hindsight.recall(\n",
    "        bank_id=USER_ID,\n",
    "        query=f\"movie preferences tastes genres {user_query}\",\n",
    "        budget=\"mid\",\n",
    "    )\n",
    "\n",
    "    # Build context from memories\n",
    "    memory_context = \"\"\n",
    "    if memories and memories.results:\n",
    "        memory_context = \"\\n\".join(\n",
    "            f\"- {m.text}\" for m in memories.results[:5]\n",
    "        )\n",
    "\n",
    "    # Generate recommendation with context\n",
    "    system_prompt = f\"\"\"You are a helpful movie recommendation assistant.\n",
    "You remember the user's preferences and past conversations to give personalized suggestions.\n",
    "\n",
    "What you know about this user:\n",
    "{memory_context if memory_context else \"No previous preferences recorded yet.\"}\n",
    "\n",
    "Give thoughtful, personalized recommendations based on their tastes.\n",
    "If they mention new preferences, acknowledge them.\"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "    recommendation = response.choices[0].message.content\n",
    "\n",
    "    # Store this interaction for future context\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"User asked: {user_query}\\nRecommendation given: {recommendation}\",\n",
    "        metadata={\"category\": \"movie_recommendation\"},\n",
    "    )\n",
    "\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def store_preference(preference: str) -> None:\n",
    "    \"\"\"Store an explicit user preference.\"\"\"\n",
    "    hindsight.retain(\n",
    "        bank_id=USER_ID,\n",
    "        content=f\"User preference: {preference}\",\n",
    "        metadata={\"category\": \"preference\"},\n",
    "    )\n",
    "    print(f\"Stored preference: {preference}\")\n",
    "\n",
    "\n",
    "def get_preference_summary() -> str:\n",
    "    \"\"\"Get a summary of what we know about the user's movie tastes.\"\"\"\n",
    "    summary = hindsight.reflect(\n",
    "        bank_id=USER_ID,\n",
    "        query=\"Summarize this user's movie preferences, favorite genres, actors they like, and movies they've mentioned enjoying or disliking.\",\n",
    "        budget=\"high\",\n",
    "    )\n",
    "    return summary.text if hasattr(summary, 'text') else str(summary)\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the Demo\n",
    "\n",
    "Watch how the assistant learns and remembers preferences across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Movie Recommendation Assistant with Memory\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Simulate a conversation over time\n",
    "conversations = [\n",
    "    \"I'm looking for a movie to watch tonight. Any suggestions?\",\n",
    "    \"I really loved Inception and Interstellar. Christopher Nolan is amazing!\",\n",
    "    \"Can you suggest something similar to those? I like mind-bending plots.\",\n",
    "    \"Actually, I'm not in the mood for something heavy. Something lighter?\",\n",
    "    \"I watched The Grand Budapest Hotel last week and loved it!\",\n",
    "    \"What should I watch tonight? Remember what I like!\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(conversations, 1):\n",
    "    print(f\"\\n[Conversation {i}]\")\n",
    "    print(f\"User: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    response = get_recommendation(query)\n",
    "    print(f\"Assistant: {response}\")\n",
    "    print()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Learned Preferences\n",
    "\n",
    "Use `reflect()` to synthesize what Hindsight has learned about your movie tastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  What I've learned about your movie tastes:\")\n",
    "print(\"=\" * 60)\n",
    "print(get_preference_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Try Your Own Queries\n",
    "\n",
    "Experiment with your own movie preferences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own query!\n",
    "your_query = \"I'm in the mood for a sci-fi thriller\"  # Change this!\n",
    "\n",
    "print(f\"You: {your_query}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Assistant: {get_recommendation(your_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "\n",
    "Close the Hindsight client connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindsight.close()\n",
    "print(\"Client connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "tags": {
   "language": "Python",
   "sdk": "Hindsight Client",
   "topic": "Recommendation"
  },
  "description": "Get personalized movie recommendations that improve over time"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}